{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d09a5f0",
   "metadata": {},
   "source": [
    "---\n",
    "## **📊 Flow**   \n",
    "> step01 : Data   \n",
    "> - 데이터 준비 및 분석   \n",
    "> - 데이터 전처리\n",
    "   #   \n",
    "> setp02 : 비교 모델    \n",
    "> - ResNet50, EfficientNet,VGG16\n",
    "> - 모델 학습\n",
    "> - 성능평가 : 정확도 재현율 f1\n",
    "   #\n",
    "> setp03 : 성능 개선   \n",
    "> ResNet50, EfficientNet,VGG16 모델들 **앙상블**   \n",
    "> 성능평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bdfc80",
   "metadata": {},
   "source": [
    "---\n",
    "> ### step01 : Data   \n",
    "> - 데이터 준비 및 분석   \n",
    "> - 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed597957",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataprocessing import *\n",
    "\n",
    "# 데이터 경로\n",
    "data_path = '/home/dibaeck/sketch/study_Data4Quality/task02_CovidClassifier/COVID19_1K'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd80077",
   "metadata": {},
   "source": [
    "---\n",
    ">> 데이터 사이즈 다름 --> TASK : 데이터 리사이즈  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84997161",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_image_sizes(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f345db94",
   "metadata": {},
   "source": [
    "---\n",
    ">> 클래스 불균형 : COVID19 데이터가 적음.  --> TASK : Data Augmentation   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb00a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_and_visualize_images(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9793bbb",
   "metadata": {},
   "source": [
    "클래스 불균형 해결 전략 : WeightedRandomSampler + FocalLoss\n",
    "\n",
    "| 전략               | 설명                                                                 |\n",
    "|--------------------|----------------------------------------------------------------------|\n",
    "| **WeightedRandomSampler**          | 수 클래스를 더 자주 뽑히게 하는 샘플링 방식                |\n",
    "| **Focal Loss**     | 소수 클래스의 어려운 샘플에 더 집중하는 loss function(의료 이미지에서 성능 개선에 효과적)                               |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503ffc26",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b111b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## setting \n",
    "from dataprocessing import *\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "# 데이터 경로\n",
    "data_path = '/home/dibaeck/sketch/study_Data4Quality/task02_CovidClassifier/COVID19_1K'\n",
    "\n",
    "# 데이터 정규화 및 리사이즈, 텐서화\n",
    "transform = get_transform()\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = get_datasets(data_path, transform)\n",
    "\n",
    "# 데이터 로더 batch size 32\n",
    "train_loader = DataLoader(train_dataset, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c5f9664",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## setting \n",
    "from dataprocessing import *\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from models import *\n",
    "\n",
    "# 데이터 경로\n",
    "data_path = '/home/dibaeck/sketch/study_Data4Quality/task02_CovidClassifier/COVID19_1K'\n",
    "\n",
    "# 데이터 정규화 및 리사이즈, 텐서화\n",
    "transform = get_transform()\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = get_datasets(data_path, transform)\n",
    "\n",
    "# 데이터 로더 batch size 32\n",
    "train_loader = DataLoader(train_dataset, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False)\n",
    "\n",
    "\n",
    "# 모델 불러오기\n",
    "# Binary Classification (PNEUMONIA vs NORMAL)\n",
    "binary_model_pneumonia_vs_normal = BasicNN(num_classes=2)\n",
    "\n",
    "# Binary Classification (COVID19 vs NORMAL)\n",
    "binary_model_covid19_vs_normal = BasicNN(num_classes=2)\n",
    "\n",
    "# Multi-class Classification (COVID19 vs PNEUMONIA vs NORMAL)\n",
    "multi_class_model = BasicNN(num_classes=3)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# 각각의 모델에 대해 이진 분류에서는 Binary Cross Entropy를, 다중 클래스 분류에서는 Cross Entropy를 사용\n",
    "\n",
    "# 이진 분류 모델 (PNEUMONIA vs NORMAL, COVID19 vs NORMAL) \n",
    "criterion_binary = nn.BCEWithLogitsLoss()  # 이진 분류에서 사용\n",
    "optimizer_binary = optim.Adam(binary_model_pneumonia_vs_normal.parameters(), lr=0.001)\n",
    "\n",
    "# 다중 클래스 분류 모델 (COVID19 vs PNEUMONIA vs NORMAL)\n",
    "criterion_multi_class = nn.CrossEntropyLoss()  # 다중 클래스 분류에서 사용\n",
    "optimizer_multi_class = optim.Adam(multi_class_model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9680e501",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "GET was unable to find an engine to execute this computation",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mbinary_model_pneumonia_vs_normal\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_train_binary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion_binary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_binary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m binary_model_covid19_vs_normal.model_train(train_loader, criterion_binary, optimizer_binary)\n\u001b[32m      6\u001b[39m multi_class_model.model_train(train_loader,criterion_multi_class,optimizer_multi_class)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sketch/study_Data4Quality/task02_CovidClassifier/models.py:47\u001b[39m, in \u001b[36mBasicNN.model_train_binary\u001b[39m\u001b[34m(self, train_loader, criterion, optimizer, num_epochs)\u001b[39m\n\u001b[32m     44\u001b[39m inputs, labels = inputs.to(\u001b[38;5;28mself\u001b[39m.device).float(), labels.to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m     46\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# CrossEntropyLoss 사용 (출력값은 [batch_size, 2], 레이블은 [batch_size])\u001b[39;00m\n\u001b[32m     50\u001b[39m loss = criterion(outputs, labels)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1496\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1499\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1500\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1501\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1502\u001b[39m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[32m   1503\u001b[39m full_backward_hooks, non_full_backward_hooks = [], []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sketch/study_Data4Quality/task02_CovidClassifier/models.py:23\u001b[39m, in \u001b[36mBasicNN.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     x = torch.relu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     24\u001b[39m     x = torch.relu(\u001b[38;5;28mself\u001b[39m.conv2(x))\n\u001b[32m     25\u001b[39m     x = torch.relu(\u001b[38;5;28mself\u001b[39m.conv3(x))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1496\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1499\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1500\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1501\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1502\u001b[39m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[32m   1503\u001b[39m full_backward_hooks, non_full_backward_hooks = [], []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/torch/nn/modules/conv.py:463\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    462\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m463\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/torch/nn/modules/conv.py:459\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m'\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(F.pad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode),\n\u001b[32m    457\u001b[39m                     weight, bias, \u001b[38;5;28mself\u001b[39m.stride,\n\u001b[32m    458\u001b[39m                     _pair(\u001b[32m0\u001b[39m), \u001b[38;5;28mself\u001b[39m.dilation, \u001b[38;5;28mself\u001b[39m.groups)\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: GET was unable to find an engine to execute this computation"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "binary_model_pneumonia_vs_normal.model_train(train_loader, criterion_binary, optimizer_binary)\n",
    "\n",
    "binary_model_covid19_vs_normal.model_train(train_loader, criterion_binary, optimizer_binary)\n",
    "\n",
    "multi_class_model.model_train(train_loader,criterion_multi_class,optimizer_multi_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a9dcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "binary_model_pneumonia_vs_normal.model_eval(test_loader)\n",
    "binary_model_covid19_vs_normal.model_eval(test_loader)\n",
    "multi_class_model.model_eval(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "126f9254",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()  # 메모리 비우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e779971a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a68ef00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1567860a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bee5d4c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7bd93a76",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "WodlWegTlmnm",
   "metadata": {
    "id": "WodlWegTlmnm"
   },
   "source": [
    "# Step 1. Pytorch 데이터 로더 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f8ffd2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "73f8ffd2",
    "outputId": "add33283-6564-42b4-d199-0cbcd2751d01"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# 전처리 정의 (흑백 이미지가 아닐 경우 3채널 RGB 기준)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# 경로 설정\n",
    "data_dir = \"/content/drive/MyDrive/Xray_image/Xray_image_small\"\n",
    "\n",
    "train_dataset = datasets.ImageFolder(os.path.join(data_dir, \"train\"), transform=transform)\n",
    "val_dataset = datasets.ImageFolder(os.path.join(data_dir, \"val\"), transform=transform)\n",
    "test_dataset = datasets.ImageFolder(os.path.join(data_dir, \"test\"), transform=transform)\n",
    "\n",
    "# 데이터 로더\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 클래스 이름 확인\n",
    "print(\"클래스 인식 결과:\", train_dataset.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UasQd29zmPrW",
   "metadata": {
    "id": "UasQd29zmPrW"
   },
   "source": [
    "# Step 2: 이미지 시각화 (정상 vs 폐렴)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y0gon2jHmNhF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 247
    },
    "id": "y0gon2jHmNhF",
    "outputId": "4b1a868d-40f4-4b1e-c86e-2f079d32fda8"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "# 이미지 일부 보기 (grid 형태)\n",
    "def show_images_from_loader(loader, class_names, n_images=6):\n",
    "    data_iter = iter(loader)\n",
    "    images, labels = next(data_iter)\n",
    "\n",
    "    # n_images만큼 자르기\n",
    "    images = images[:n_images]\n",
    "    labels = labels[:n_images]\n",
    "\n",
    "    # 역정규화\n",
    "    images = images * 0.5 + 0.5\n",
    "\n",
    "    # 시각화\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i in range(n_images):\n",
    "        img = images[i].permute(1, 2, 0).numpy()\n",
    "        label = class_names[labels[i].item()]\n",
    "        plt.subplot(1, n_images, i+1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(label)\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(\"Chest X-ray Sample Images\")\n",
    "    plt.show()\n",
    "\n",
    "# 실행\n",
    "show_images_from_loader(train_loader, train_dataset.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jBpjvuOxmpRT",
   "metadata": {
    "id": "jBpjvuOxmpRT"
   },
   "source": [
    "# Step 3: 기본 CNN 모델 정의 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sqhLenf6fuz3",
   "metadata": {
    "id": "sqhLenf6fuz3"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BasicCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(32 * 56 * 56, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # -> (16, 112, 112)\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # -> (32, 56, 56)\n",
    "        x = x.view(-1, 32 * 56 * 56)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_2t7S5hSmyYH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_2t7S5hSmyYH",
    "outputId": "8d38de0c-e3b6-46ab-dac3-5ae2e4d46b40"
   },
   "outputs": [],
   "source": [
    "# CNN 모델 학습\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BasicCNN().to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(20):  # 에폭 수 조절 가능\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.float().unsqueeze(1).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}] Loss: {running_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ov66g2I4m1SI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ov66g2I4m1SI",
    "outputId": "c87c1844-463e-4325-f427-b86497832800"
   },
   "outputs": [],
   "source": [
    "#Accuracy 측정\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = (outputs > 0.5).int().squeeze()\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    acc = correct / total\n",
    "    print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "\n",
    "# 실행\n",
    "evaluate(model, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Wa3MLPHzrMuN",
   "metadata": {
    "id": "Wa3MLPHzrMuN"
   },
   "source": [
    "# Step 4: Pretrained 모델 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_KympUPPq-vi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_KympUPPq-vi",
    "outputId": "62e975d6-0133-4996-83c1-367616eaa5a9"
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 사전학습된 DenseNet121 불러오기\n",
    "densenet = models.densenet121(pretrained=True)\n",
    "\n",
    "# 마지막 분류 레이어 수정 (binary classification)\n",
    "num_ftrs = densenet.classifier.in_features\n",
    "densenet.classifier = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "densenet = densenet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UOFqy8PArTlj",
   "metadata": {
    "id": "UOFqy8PArTlj"
   },
   "outputs": [],
   "source": [
    "#학습 준비 - loss, optimizer 정의\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(densenet.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3xcKxF87rZWa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3xcKxF87rZWa",
    "outputId": "3cb48035-129d-4be1-ea51-294eb5b5e0b5"
   },
   "outputs": [],
   "source": [
    "for epoch in range(20):  # 에폭 수 조절 가능\n",
    "    densenet.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.float().unsqueeze(1).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = densenet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}] Loss: {running_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xfPkvzhkrb8e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xfPkvzhkrb8e",
    "outputId": "b92317d8-a9c8-4062-cadb-c76e4781c7a6"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = (outputs > 0.5).int().squeeze()\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    acc = correct / total\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "\n",
    "# 실행\n",
    "print(\"Validation Set:\")\n",
    "evaluate(densenet, val_loader)\n",
    "print(\"Test Set:\")\n",
    "evaluate(densenet, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TakbwOOVtnsI",
   "metadata": {
    "id": "TakbwOOVtnsI"
   },
   "source": [
    "#Step 5: 결과 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kt2niO2Vrqzt",
   "metadata": {
    "id": "Kt2niO2Vrqzt"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 모델 평가 모드\n",
    "densenet.eval()\n",
    "\n",
    "# 예측 결과 저장용 리스트\n",
    "all_preds = []\n",
    "all_probs = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = densenet(inputs)\n",
    "\n",
    "        probs = outputs.cpu().numpy().flatten()\n",
    "        preds = (outputs > 0.5).int().cpu().numpy().flatten()\n",
    "        labels = labels.cpu().numpy().flatten()\n",
    "\n",
    "        all_probs.extend(probs)\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "all_preds = np.array(all_preds)\n",
    "all_probs = np.array(all_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SubywV1xtXxl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "SubywV1xtXxl",
    "outputId": "169910d1-9280-492e-d6bb-7b4f9e3af971"
   },
   "outputs": [],
   "source": [
    "# 혼동 행렬 계산\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Normal\", \"Pneumonia\"])\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(6, 6))\n",
    "disp.plot(cmap=\"Blues\", values_format='d')\n",
    "plt.title(\"Confusion Matrix - DenseNet\")\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zNUoNUq8tZFZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "zNUoNUq8tZFZ",
    "outputId": "e62ad284-fa03-49e6-967b-6944dc609a57"
   },
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "roc_auc = roc_auc_score(all_labels, all_probs)\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate (Recall)\")\n",
    "plt.title(\"ROC Curve - DenseNet\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LDFbWosTts7h",
   "metadata": {
    "id": "LDFbWosTts7h"
   },
   "source": [
    "# Step 6: GradCAM 시각화 - 해석력 강화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QyC1yLpetglB",
   "metadata": {
    "id": "QyC1yLpetglB"
   },
   "outputs": [],
   "source": [
    "# 1. Grad-CAM 유틸리티 함수\n",
    "import cv2\n",
    "def generate_gradcam(model, input_tensor, target_class, target_layer):\n",
    "    model.eval()\n",
    "    gradients = []\n",
    "    activations = []\n",
    "\n",
    "    def backward_hook(module, grad_input, grad_output):\n",
    "        gradients.append(grad_output[0].detach())\n",
    "\n",
    "    def forward_hook(module, input, output):\n",
    "        activations.append(output.detach())\n",
    "\n",
    "    # Hook 등록\n",
    "    handle_fw = target_layer.register_forward_hook(forward_hook)\n",
    "    handle_bw = target_layer.register_backward_hook(backward_hook)\n",
    "\n",
    "    # Forward\n",
    "    output = model(input_tensor)\n",
    "    model.zero_grad()\n",
    "    loss = output[0][0] if target_class is None else output[0, target_class]\n",
    "    loss.backward()\n",
    "\n",
    "    # Hook 해제\n",
    "    handle_fw.remove()\n",
    "    handle_bw.remove()\n",
    "\n",
    "    # Grad-CAM 계산\n",
    "    grads = gradients[0]  # shape: [B, C, H, W]\n",
    "    acts = activations[0] # shape: [B, C, H, W]\n",
    "    pooled_grads = torch.mean(grads, dim=[0, 2, 3])  # shape: [C]\n",
    "\n",
    "    # weighted sum\n",
    "    for i in range(acts.shape[1]):\n",
    "        acts[:, i, :, :] *= pooled_grads[i]\n",
    "\n",
    "    heatmap = torch.mean(acts, dim=1).squeeze()\n",
    "    heatmap = np.maximum(heatmap.cpu().numpy(), 0)\n",
    "    heatmap /= np.max(heatmap)\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ma2yDTwtuU8v",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ma2yDTwtuU8v",
    "outputId": "46541883-d8d0-4293-a4da-ac013cf47e4c"
   },
   "outputs": [],
   "source": [
    "#예측값 & 정답 필터링 → 폐렴을 정확히 맞춘 샘플 찾기\n",
    "correct_indices = []\n",
    "sample_imgs = []\n",
    "sample_labels = []\n",
    "\n",
    "# test_dataset 전체 탐색\n",
    "for i in range(len(test_dataset)):\n",
    "    img, label = test_dataset[i]\n",
    "    input_tensor = img.unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = densenet(input_tensor)\n",
    "        pred = (output > 0.5).int().item()\n",
    "\n",
    "    # 폐렴이고 예측도 폐렴이면 저장\n",
    "    if label == 1 and pred == 1:\n",
    "        correct_indices.append(i)\n",
    "        sample_imgs.append(img)\n",
    "        sample_labels.append(label)\n",
    "\n",
    "print(f\"폐렴 → 폐렴으로 정확히 맞춘 샘플 개수: {len(correct_indices)}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EcvjflkQt1qj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 837
    },
    "id": "EcvjflkQt1qj",
    "outputId": "af0a4870-4e7e-4bf1-88ac-39295b6613de"
   },
   "outputs": [],
   "source": [
    "#2) Grad-CAM 적용 예제 (DenseNet의 마지막 conv layer 사용)\n",
    "# 예: 맞춘 것 중 0~2번 샘플 시각화\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(min(3, len(sample_imgs))):  # 최대 3개까지만 예시\n",
    "    img = sample_imgs[i]\n",
    "    input_tensor = img.unsqueeze(0).to(device)\n",
    "\n",
    "    heatmap = generate_gradcam(densenet, input_tensor, target_class=None, target_layer=densenet.features[-1])\n",
    "\n",
    "    # 원본 이미지\n",
    "    img_np = img.permute(1, 2, 0).numpy()\n",
    "    img_np = img_np * 0.5 + 0.5  # 역정규화\n",
    "\n",
    "    # Heatmap → 컬러맵 적용\n",
    "    heatmap_resized = cv2.resize(heatmap, (img_np.shape[1], img_np.shape[0]))\n",
    "    heatmap_colored = cv2.applyColorMap(np.uint8(255 * heatmap_resized), cv2.COLORMAP_JET)\n",
    "    overlay = 0.4 * heatmap_colored / 255.0 + 0.6 * img_np\n",
    "\n",
    "    # 시각화\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(img_np)\n",
    "    plt.title(\"Original X-ray\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(heatmap_resized, cmap='jet')\n",
    "    plt.title(\"Grad-CAM Heatmap\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(np.clip(overlay, 0, 1))\n",
    "    plt.title(\"Overlay\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mZanYKZqt-n5",
   "metadata": {
    "id": "mZanYKZqt-n5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dibk311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
