{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d09a5f0",
   "metadata": {},
   "source": [
    "---\n",
    "## **ğŸ“Š Flow**   \n",
    "> step01 : Data   \n",
    "> - ë°ì´í„° ì¤€ë¹„ ë° ë¶„ì„   \n",
    "> - ë°ì´í„° ì „ì²˜ë¦¬\n",
    "   #   \n",
    "> setp02 : ë¹„êµ ëª¨ë¸    \n",
    "> - ResNet50, EfficientNet,VGG16\n",
    "> - ëª¨ë¸ í•™ìŠµ\n",
    "> - ì„±ëŠ¥í‰ê°€ : ì •í™•ë„ ì¬í˜„ìœ¨ f1\n",
    "   #\n",
    "> setp03 : ì„±ëŠ¥ ê°œì„    \n",
    "> ResNet50, EfficientNet,VGG16 ëª¨ë¸ë“¤ **ì•™ìƒë¸”**   \n",
    "> ì„±ëŠ¥í‰ê°€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bdfc80",
   "metadata": {},
   "source": [
    "---\n",
    "> ### step01 : Data   \n",
    "> - ë°ì´í„° ì¤€ë¹„ ë° ë¶„ì„   \n",
    "> - ë°ì´í„° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed597957",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataprocessing import *\n",
    "\n",
    "# ë°ì´í„° ê²½ë¡œ\n",
    "data_path = '/home/dibaeck/sketch/study_Data4Quality/task02_CovidClassifier/COVID19_1K'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd80077",
   "metadata": {},
   "source": [
    "---\n",
    ">> ë°ì´í„° ì‚¬ì´ì¦ˆ ë‹¤ë¦„ --> TASK : ë°ì´í„° ë¦¬ì‚¬ì´ì¦ˆ  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84997161",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_image_sizes(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f345db94",
   "metadata": {},
   "source": [
    "---\n",
    ">> í´ë˜ìŠ¤ ë¶ˆê· í˜• : COVID19 ë°ì´í„°ê°€ ì ìŒ.  --> TASK : Data Augmentation   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb00a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_and_visualize_images(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9793bbb",
   "metadata": {},
   "source": [
    "í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²° ì „ëµ : WeightedRandomSampler + FocalLoss\n",
    "\n",
    "| ì „ëµ               | ì„¤ëª…                                                                 |\n",
    "|--------------------|----------------------------------------------------------------------|\n",
    "| **WeightedRandomSampler**          | ìˆ˜ í´ë˜ìŠ¤ë¥¼ ë” ìì£¼ ë½‘íˆê²Œ í•˜ëŠ” ìƒ˜í”Œë§ ë°©ì‹                |\n",
    "| **Focal Loss**     | ì†Œìˆ˜ í´ë˜ìŠ¤ì˜ ì–´ë ¤ìš´ ìƒ˜í”Œì— ë” ì§‘ì¤‘í•˜ëŠ” loss function(ì˜ë£Œ ì´ë¯¸ì§€ì—ì„œ ì„±ëŠ¥ ê°œì„ ì— íš¨ê³¼ì )                               |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503ffc26",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b111b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## setting \n",
    "from dataprocessing import *\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "# ë°ì´í„° ê²½ë¡œ\n",
    "data_path = '/home/dibaeck/sketch/study_Data4Quality/task02_CovidClassifier/COVID19_1K'\n",
    "\n",
    "# ë°ì´í„° ì •ê·œí™” ë° ë¦¬ì‚¬ì´ì¦ˆ, í…ì„œí™”\n",
    "transform = get_transform()\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = get_datasets(data_path, transform)\n",
    "\n",
    "# ë°ì´í„° ë¡œë” batch size 32\n",
    "train_loader = DataLoader(train_dataset, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c5f9664",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## setting \n",
    "from dataprocessing import *\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from models import *\n",
    "\n",
    "# ë°ì´í„° ê²½ë¡œ\n",
    "data_path = '/home/dibaeck/sketch/study_Data4Quality/task02_CovidClassifier/COVID19_1K'\n",
    "\n",
    "# ë°ì´í„° ì •ê·œí™” ë° ë¦¬ì‚¬ì´ì¦ˆ, í…ì„œí™”\n",
    "transform = get_transform()\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = get_datasets(data_path, transform)\n",
    "\n",
    "# ë°ì´í„° ë¡œë” batch size 32\n",
    "train_loader = DataLoader(train_dataset, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False)\n",
    "\n",
    "\n",
    "# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# Binary Classification (PNEUMONIA vs NORMAL)\n",
    "binary_model_pneumonia_vs_normal = BasicNN(num_classes=2)\n",
    "\n",
    "# Binary Classification (COVID19 vs NORMAL)\n",
    "binary_model_covid19_vs_normal = BasicNN(num_classes=2)\n",
    "\n",
    "# Multi-class Classification (COVID19 vs PNEUMONIA vs NORMAL)\n",
    "multi_class_model = BasicNN(num_classes=3)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# ê°ê°ì˜ ëª¨ë¸ì— ëŒ€í•´ ì´ì§„ ë¶„ë¥˜ì—ì„œëŠ” Binary Cross Entropyë¥¼, ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ì—ì„œëŠ” Cross Entropyë¥¼ ì‚¬ìš©\n",
    "\n",
    "# ì´ì§„ ë¶„ë¥˜ ëª¨ë¸ (PNEUMONIA vs NORMAL, COVID19 vs NORMAL) \n",
    "criterion_binary = nn.BCEWithLogitsLoss()  # ì´ì§„ ë¶„ë¥˜ì—ì„œ ì‚¬ìš©\n",
    "optimizer_binary = optim.Adam(binary_model_pneumonia_vs_normal.parameters(), lr=0.001)\n",
    "\n",
    "# ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ ëª¨ë¸ (COVID19 vs PNEUMONIA vs NORMAL)\n",
    "criterion_multi_class = nn.CrossEntropyLoss()  # ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ì—ì„œ ì‚¬ìš©\n",
    "optimizer_multi_class = optim.Adam(multi_class_model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9680e501",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "GET was unable to find an engine to execute this computation",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ëª¨ë¸ í•™ìŠµ\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mbinary_model_pneumonia_vs_normal\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_train_binary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion_binary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_binary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m binary_model_covid19_vs_normal.model_train(train_loader, criterion_binary, optimizer_binary)\n\u001b[32m      6\u001b[39m multi_class_model.model_train(train_loader,criterion_multi_class,optimizer_multi_class)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sketch/study_Data4Quality/task02_CovidClassifier/models.py:47\u001b[39m, in \u001b[36mBasicNN.model_train_binary\u001b[39m\u001b[34m(self, train_loader, criterion, optimizer, num_epochs)\u001b[39m\n\u001b[32m     44\u001b[39m inputs, labels = inputs.to(\u001b[38;5;28mself\u001b[39m.device).float(), labels.to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m     46\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# CrossEntropyLoss ì‚¬ìš© (ì¶œë ¥ê°’ì€ [batch_size, 2], ë ˆì´ë¸”ì€ [batch_size])\u001b[39;00m\n\u001b[32m     50\u001b[39m loss = criterion(outputs, labels)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1496\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1499\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1500\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1501\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1502\u001b[39m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[32m   1503\u001b[39m full_backward_hooks, non_full_backward_hooks = [], []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sketch/study_Data4Quality/task02_CovidClassifier/models.py:23\u001b[39m, in \u001b[36mBasicNN.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     x = torch.relu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     24\u001b[39m     x = torch.relu(\u001b[38;5;28mself\u001b[39m.conv2(x))\n\u001b[32m     25\u001b[39m     x = torch.relu(\u001b[38;5;28mself\u001b[39m.conv3(x))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1496\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1499\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1500\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1501\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1502\u001b[39m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[32m   1503\u001b[39m full_backward_hooks, non_full_backward_hooks = [], []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/torch/nn/modules/conv.py:463\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    462\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m463\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/torch/nn/modules/conv.py:459\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m'\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(F.pad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode),\n\u001b[32m    457\u001b[39m                     weight, bias, \u001b[38;5;28mself\u001b[39m.stride,\n\u001b[32m    458\u001b[39m                     _pair(\u001b[32m0\u001b[39m), \u001b[38;5;28mself\u001b[39m.dilation, \u001b[38;5;28mself\u001b[39m.groups)\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: GET was unable to find an engine to execute this computation"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ í•™ìŠµ\n",
    "binary_model_pneumonia_vs_normal.model_train(train_loader, criterion_binary, optimizer_binary)\n",
    "\n",
    "binary_model_covid19_vs_normal.model_train(train_loader, criterion_binary, optimizer_binary)\n",
    "\n",
    "multi_class_model.model_train(train_loader,criterion_multi_class,optimizer_multi_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a9dcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ í‰ê°€\n",
    "binary_model_pneumonia_vs_normal.model_eval(test_loader)\n",
    "binary_model_covid19_vs_normal.model_eval(test_loader)\n",
    "multi_class_model.model_eval(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "126f9254",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()  # ë©”ëª¨ë¦¬ ë¹„ìš°ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e779971a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a68ef00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1567860a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bee5d4c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7bd93a76",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "WodlWegTlmnm",
   "metadata": {
    "id": "WodlWegTlmnm"
   },
   "source": [
    "# Step 1. Pytorch ë°ì´í„° ë¡œë” ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f8ffd2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "73f8ffd2",
    "outputId": "add33283-6564-42b4-d199-0cbcd2751d01"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# ì „ì²˜ë¦¬ ì •ì˜ (í‘ë°± ì´ë¯¸ì§€ê°€ ì•„ë‹ ê²½ìš° 3ì±„ë„ RGB ê¸°ì¤€)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# ê²½ë¡œ ì„¤ì •\n",
    "data_dir = \"/content/drive/MyDrive/Xray_image/Xray_image_small\"\n",
    "\n",
    "train_dataset = datasets.ImageFolder(os.path.join(data_dir, \"train\"), transform=transform)\n",
    "val_dataset = datasets.ImageFolder(os.path.join(data_dir, \"val\"), transform=transform)\n",
    "test_dataset = datasets.ImageFolder(os.path.join(data_dir, \"test\"), transform=transform)\n",
    "\n",
    "# ë°ì´í„° ë¡œë”\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# í´ë˜ìŠ¤ ì´ë¦„ í™•ì¸\n",
    "print(\"í´ë˜ìŠ¤ ì¸ì‹ ê²°ê³¼:\", train_dataset.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UasQd29zmPrW",
   "metadata": {
    "id": "UasQd29zmPrW"
   },
   "source": [
    "# Step 2: ì´ë¯¸ì§€ ì‹œê°í™” (ì •ìƒ vs íë ´)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y0gon2jHmNhF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 247
    },
    "id": "y0gon2jHmNhF",
    "outputId": "4b1a868d-40f4-4b1e-c86e-2f079d32fda8"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "# ì´ë¯¸ì§€ ì¼ë¶€ ë³´ê¸° (grid í˜•íƒœ)\n",
    "def show_images_from_loader(loader, class_names, n_images=6):\n",
    "    data_iter = iter(loader)\n",
    "    images, labels = next(data_iter)\n",
    "\n",
    "    # n_imagesë§Œí¼ ìë¥´ê¸°\n",
    "    images = images[:n_images]\n",
    "    labels = labels[:n_images]\n",
    "\n",
    "    # ì—­ì •ê·œí™”\n",
    "    images = images * 0.5 + 0.5\n",
    "\n",
    "    # ì‹œê°í™”\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i in range(n_images):\n",
    "        img = images[i].permute(1, 2, 0).numpy()\n",
    "        label = class_names[labels[i].item()]\n",
    "        plt.subplot(1, n_images, i+1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(label)\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(\"Chest X-ray Sample Images\")\n",
    "    plt.show()\n",
    "\n",
    "# ì‹¤í–‰\n",
    "show_images_from_loader(train_loader, train_dataset.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jBpjvuOxmpRT",
   "metadata": {
    "id": "jBpjvuOxmpRT"
   },
   "source": [
    "# Step 3: ê¸°ë³¸ CNN ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sqhLenf6fuz3",
   "metadata": {
    "id": "sqhLenf6fuz3"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BasicCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(32 * 56 * 56, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # -> (16, 112, 112)\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # -> (32, 56, 56)\n",
    "        x = x.view(-1, 32 * 56 * 56)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_2t7S5hSmyYH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_2t7S5hSmyYH",
    "outputId": "8d38de0c-e3b6-46ab-dac3-5ae2e4d46b40"
   },
   "outputs": [],
   "source": [
    "# CNN ëª¨ë¸ í•™ìŠµ\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BasicCNN().to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(20):  # ì—í­ ìˆ˜ ì¡°ì ˆ ê°€ëŠ¥\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.float().unsqueeze(1).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}] Loss: {running_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ov66g2I4m1SI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ov66g2I4m1SI",
    "outputId": "c87c1844-463e-4325-f427-b86497832800"
   },
   "outputs": [],
   "source": [
    "#Accuracy ì¸¡ì •\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = (outputs > 0.5).int().squeeze()\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    acc = correct / total\n",
    "    print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "\n",
    "# ì‹¤í–‰\n",
    "evaluate(model, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Wa3MLPHzrMuN",
   "metadata": {
    "id": "Wa3MLPHzrMuN"
   },
   "source": [
    "# Step 4: Pretrained ëª¨ë¸ í™œìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_KympUPPq-vi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_KympUPPq-vi",
    "outputId": "62e975d6-0133-4996-83c1-367616eaa5a9"
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# ì‚¬ì „í•™ìŠµëœ DenseNet121 ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "densenet = models.densenet121(pretrained=True)\n",
    "\n",
    "# ë§ˆì§€ë§‰ ë¶„ë¥˜ ë ˆì´ì–´ ìˆ˜ì • (binary classification)\n",
    "num_ftrs = densenet.classifier.in_features\n",
    "densenet.classifier = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "densenet = densenet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UOFqy8PArTlj",
   "metadata": {
    "id": "UOFqy8PArTlj"
   },
   "outputs": [],
   "source": [
    "#í•™ìŠµ ì¤€ë¹„ - loss, optimizer ì •ì˜\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(densenet.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3xcKxF87rZWa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3xcKxF87rZWa",
    "outputId": "3cb48035-129d-4be1-ea51-294eb5b5e0b5"
   },
   "outputs": [],
   "source": [
    "for epoch in range(20):  # ì—í­ ìˆ˜ ì¡°ì ˆ ê°€ëŠ¥\n",
    "    densenet.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.float().unsqueeze(1).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = densenet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}] Loss: {running_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xfPkvzhkrb8e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xfPkvzhkrb8e",
    "outputId": "b92317d8-a9c8-4062-cadb-c76e4781c7a6"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = (outputs > 0.5).int().squeeze()\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    acc = correct / total\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "\n",
    "# ì‹¤í–‰\n",
    "print(\"Validation Set:\")\n",
    "evaluate(densenet, val_loader)\n",
    "print(\"Test Set:\")\n",
    "evaluate(densenet, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TakbwOOVtnsI",
   "metadata": {
    "id": "TakbwOOVtnsI"
   },
   "source": [
    "#Step 5: ê²°ê³¼ ì •ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kt2niO2Vrqzt",
   "metadata": {
    "id": "Kt2niO2Vrqzt"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ëª¨ë¸ í‰ê°€ ëª¨ë“œ\n",
    "densenet.eval()\n",
    "\n",
    "# ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸\n",
    "all_preds = []\n",
    "all_probs = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = densenet(inputs)\n",
    "\n",
    "        probs = outputs.cpu().numpy().flatten()\n",
    "        preds = (outputs > 0.5).int().cpu().numpy().flatten()\n",
    "        labels = labels.cpu().numpy().flatten()\n",
    "\n",
    "        all_probs.extend(probs)\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "all_preds = np.array(all_preds)\n",
    "all_probs = np.array(all_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SubywV1xtXxl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "SubywV1xtXxl",
    "outputId": "169910d1-9280-492e-d6bb-7b4f9e3af971"
   },
   "outputs": [],
   "source": [
    "# í˜¼ë™ í–‰ë ¬ ê³„ì‚°\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Normal\", \"Pneumonia\"])\n",
    "\n",
    "# ì‹œê°í™”\n",
    "plt.figure(figsize=(6, 6))\n",
    "disp.plot(cmap=\"Blues\", values_format='d')\n",
    "plt.title(\"Confusion Matrix - DenseNet\")\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zNUoNUq8tZFZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "zNUoNUq8tZFZ",
    "outputId": "e62ad284-fa03-49e6-967b-6944dc609a57"
   },
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "roc_auc = roc_auc_score(all_labels, all_probs)\n",
    "\n",
    "# ì‹œê°í™”\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate (Recall)\")\n",
    "plt.title(\"ROC Curve - DenseNet\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LDFbWosTts7h",
   "metadata": {
    "id": "LDFbWosTts7h"
   },
   "source": [
    "# Step 6: GradCAM ì‹œê°í™” - í•´ì„ë ¥ ê°•í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QyC1yLpetglB",
   "metadata": {
    "id": "QyC1yLpetglB"
   },
   "outputs": [],
   "source": [
    "# 1. Grad-CAM ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜\n",
    "import cv2\n",
    "def generate_gradcam(model, input_tensor, target_class, target_layer):\n",
    "    model.eval()\n",
    "    gradients = []\n",
    "    activations = []\n",
    "\n",
    "    def backward_hook(module, grad_input, grad_output):\n",
    "        gradients.append(grad_output[0].detach())\n",
    "\n",
    "    def forward_hook(module, input, output):\n",
    "        activations.append(output.detach())\n",
    "\n",
    "    # Hook ë“±ë¡\n",
    "    handle_fw = target_layer.register_forward_hook(forward_hook)\n",
    "    handle_bw = target_layer.register_backward_hook(backward_hook)\n",
    "\n",
    "    # Forward\n",
    "    output = model(input_tensor)\n",
    "    model.zero_grad()\n",
    "    loss = output[0][0] if target_class is None else output[0, target_class]\n",
    "    loss.backward()\n",
    "\n",
    "    # Hook í•´ì œ\n",
    "    handle_fw.remove()\n",
    "    handle_bw.remove()\n",
    "\n",
    "    # Grad-CAM ê³„ì‚°\n",
    "    grads = gradients[0]  # shape: [B, C, H, W]\n",
    "    acts = activations[0] # shape: [B, C, H, W]\n",
    "    pooled_grads = torch.mean(grads, dim=[0, 2, 3])  # shape: [C]\n",
    "\n",
    "    # weighted sum\n",
    "    for i in range(acts.shape[1]):\n",
    "        acts[:, i, :, :] *= pooled_grads[i]\n",
    "\n",
    "    heatmap = torch.mean(acts, dim=1).squeeze()\n",
    "    heatmap = np.maximum(heatmap.cpu().numpy(), 0)\n",
    "    heatmap /= np.max(heatmap)\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ma2yDTwtuU8v",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ma2yDTwtuU8v",
    "outputId": "46541883-d8d0-4293-a4da-ac013cf47e4c"
   },
   "outputs": [],
   "source": [
    "#ì˜ˆì¸¡ê°’ & ì •ë‹µ í•„í„°ë§ â†’ íë ´ì„ ì •í™•íˆ ë§ì¶˜ ìƒ˜í”Œ ì°¾ê¸°\n",
    "correct_indices = []\n",
    "sample_imgs = []\n",
    "sample_labels = []\n",
    "\n",
    "# test_dataset ì „ì²´ íƒìƒ‰\n",
    "for i in range(len(test_dataset)):\n",
    "    img, label = test_dataset[i]\n",
    "    input_tensor = img.unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = densenet(input_tensor)\n",
    "        pred = (output > 0.5).int().item()\n",
    "\n",
    "    # íë ´ì´ê³  ì˜ˆì¸¡ë„ íë ´ì´ë©´ ì €ì¥\n",
    "    if label == 1 and pred == 1:\n",
    "        correct_indices.append(i)\n",
    "        sample_imgs.append(img)\n",
    "        sample_labels.append(label)\n",
    "\n",
    "print(f\"íë ´ â†’ íë ´ìœ¼ë¡œ ì •í™•íˆ ë§ì¶˜ ìƒ˜í”Œ ê°œìˆ˜: {len(correct_indices)}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EcvjflkQt1qj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 837
    },
    "id": "EcvjflkQt1qj",
    "outputId": "af0a4870-4e7e-4bf1-88ac-39295b6613de"
   },
   "outputs": [],
   "source": [
    "#2) Grad-CAM ì ìš© ì˜ˆì œ (DenseNetì˜ ë§ˆì§€ë§‰ conv layer ì‚¬ìš©)\n",
    "# ì˜ˆ: ë§ì¶˜ ê²ƒ ì¤‘ 0~2ë²ˆ ìƒ˜í”Œ ì‹œê°í™”\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(min(3, len(sample_imgs))):  # ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ ì˜ˆì‹œ\n",
    "    img = sample_imgs[i]\n",
    "    input_tensor = img.unsqueeze(0).to(device)\n",
    "\n",
    "    heatmap = generate_gradcam(densenet, input_tensor, target_class=None, target_layer=densenet.features[-1])\n",
    "\n",
    "    # ì›ë³¸ ì´ë¯¸ì§€\n",
    "    img_np = img.permute(1, 2, 0).numpy()\n",
    "    img_np = img_np * 0.5 + 0.5  # ì—­ì •ê·œí™”\n",
    "\n",
    "    # Heatmap â†’ ì»¬ëŸ¬ë§µ ì ìš©\n",
    "    heatmap_resized = cv2.resize(heatmap, (img_np.shape[1], img_np.shape[0]))\n",
    "    heatmap_colored = cv2.applyColorMap(np.uint8(255 * heatmap_resized), cv2.COLORMAP_JET)\n",
    "    overlay = 0.4 * heatmap_colored / 255.0 + 0.6 * img_np\n",
    "\n",
    "    # ì‹œê°í™”\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(img_np)\n",
    "    plt.title(\"Original X-ray\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(heatmap_resized, cmap='jet')\n",
    "    plt.title(\"Grad-CAM Heatmap\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(np.clip(overlay, 0, 1))\n",
    "    plt.title(\"Overlay\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mZanYKZqt-n5",
   "metadata": {
    "id": "mZanYKZqt-n5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dibk311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
