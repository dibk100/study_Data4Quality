{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4980a134",
   "metadata": {},
   "source": [
    "# Q2. MachineLearning/DeepLearning Analysis   \n",
    "\n",
    ">> background : 결측치 처리 완료함(Data_01_imputed_result.csv)\n",
    "   #\n",
    "1. Multi-task Learning (Multi-label Classification)   \n",
    "당뇨 및 고혈압 유병 분류 문제에서 single-label을 고려하는 것이 아닌, 두 종류의 label을 함께 고려하는 multi-task learning (multi-label classification) 분석을 수행하기.\n",
    "> single-label로 분석할 때와 비교.\n",
    "\n",
    "2. 생체 나이 추정 모델   \n",
    "동일 데이터에 대해 나이(AGE 변수)를 예측하는 모델로 태스크를 변경하여 생체 나이 추정 모형을 만들기.\n",
    "> 이 과정에서 데이터의 구조가 어떻게 변화하는지 설명하고, 나이 예측 모델에 맞는 성능 지표의 결과를 제시하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f26e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score,f1_score, roc_auc_score,hamming_loss\n",
    "\n",
    "# 데이터 확인\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"./Data_01_imputed_result.csv\")\n",
    "\n",
    "# print(data.head())  # 데이터 일부 출력\n",
    "# print(data.info())  # 데이터 정보 출력\n",
    "# print(data.describe())  # 데이터 통계 정보 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae1bba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 불균형 확인\n",
    "print(data['Target_DM'].value_counts())\n",
    "print(data['Target_HT'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96e04d1",
   "metadata": {},
   "source": [
    "---\n",
    "## **📊 Flow1**   \n",
    "> step01 : dataprocessing      \n",
    "> - Target_DM(0,1), Target_HT(0,1) : [1,0] 당뇨 있고 고혈압 없음.\n",
    "> - 두 레이블을 조합으로 하나의 열로 만들기\n",
    "   #   \n",
    "> setp02 : Multi-label 분류기 개발   \n",
    "> - MLP based\n",
    "   #\n",
    "> setp03 : 평가 지표   \n",
    "> - 개별 지표: 두 라벨에 대해 각각 Accuracy, F1-score, ROC-AUC\n",
    "> - 전체 지표: hamming loss, exact match ratio\n",
    "   #\n",
    "> setp04 : 모델 비교 및 결과 분석   \n",
    "> - Multi-task 모델 vs. 개별 Binary Classifier 비교\n",
    "> - confusion matrix, ROC curve 등 시각화\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edb97ab",
   "metadata": {},
   "source": [
    "---\n",
    "> ## step01 : dataprocessing      \n",
    "> - Target_DM(0,1), Target_HT(0,1) : [1,0] 당뇨 있고 고혈압 없음.\n",
    "> - 두 레이블을 조합으로 하나의 열로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011abcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 확인\n",
    "data = pd.read_csv(\"./Data_01_imputed_result.csv\")\n",
    "df = data.copy()\n",
    "\n",
    "# 입력/타겟 변수\n",
    "X = df.drop(columns=['Target_DM', 'Target_HT']).values  # 입력값\n",
    "y = data[['Target_DM', 'Target_HT']].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a044030a",
   "metadata": {},
   "source": [
    "> ## setp02 : Multi-label classifier 설계\n",
    "> - 단일 모델이 두 개의 출력을 예측함 (sigmoid 두 개)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe358cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습/테스트 분할 (멀티 라벨이므로 타겟도 같이 나눔)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dfe00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train에서 각각 레이블 분리\n",
    "y_dm_train = y_train[:, 0]   # Target_DM\n",
    "y_ht_train = y_train[:, 1]   # Target_HT\n",
    "\n",
    "# y_dm_test = \n",
    "y_dm_test = y_test[:, 0]   # Target_DM\n",
    "y_ht_test = y_test[:, 1]   # Target_HT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe18ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from impute_model import *\n",
    "\n",
    "classifier = MultiLabelClassifier(input_dim = X_train.shape[1])\n",
    "classifier.model_train_fixed_hyperparameter(X_train,y_dm_train,y_ht_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267ca20b",
   "metadata": {},
   "source": [
    "> ## setp03 : 평가 지표   \n",
    "> - 개별 지표: 두 라벨에 대해 각각 Accuracy, F1-score, ROC-AUC\n",
    "> - 전체 지표: hamming loss, exact match ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a10c23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'     # gpu \n",
    "if device!='cuda':\n",
    "    raise RuntimeError(\"CUDA device not available. Please check if a GPU is available.\")\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "\n",
    "classifier.eval()\n",
    "with torch.no_grad():\n",
    "    pred_dm, pred_ht = classifier(X_test_tensor)\n",
    "    pred_dm = pred_dm.squeeze().cpu().numpy()\n",
    "    pred_ht = pred_ht.squeeze().cpu().numpy()\n",
    "    \n",
    "# 이진화 (threshold = 0.5)\n",
    "pred_dm_binary = (pred_dm >= 0.5).astype(int)\n",
    "pred_ht_binary = (pred_ht >= 0.5).astype(int)\n",
    "\n",
    "# 개별 지표\n",
    "print(\"📌 Target_DM Accuracy:\", accuracy_score(y_dm_test, pred_dm_binary))\n",
    "print(\"📌 Target_HT Accuracy:\", accuracy_score(y_ht_test, pred_ht_binary))\n",
    "print(\"📌 Target_DM F1:\", f1_score(y_dm_test, pred_dm_binary))\n",
    "print(\"📌 Target_HT F1:\", f1_score(y_ht_test, pred_ht_binary))\n",
    "print(\"📌 Target_DM AUC:\", roc_auc_score(y_dm_test, pred_dm))\n",
    "print(\"📌 Target_HT AUC:\", roc_auc_score(y_ht_test, pred_ht))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3477b283",
   "metadata": {},
   "source": [
    "| 지표               | Target_DM        | Target_HT        |\n",
    "|--------------------|------------------|------------------|\n",
    "| **Accuracy**       | 0.9567           | 0.8929           |\n",
    "| **F1 Score**       | 0.1643           | 0.0047           |\n",
    "| **AUC**            | 0.8864           | 0.8718           |\n",
    "   #\n",
    "결론:   \n",
    "정확도는 두 레이블 모두 꽤 높은 성능을 보였으나, F1 점수가 매우 낮아서 불균형 클래스 문제나 다른 성능 지표에서 성능 저하가 있을 가능성이 큽니다.   \n",
    "특히 Target_HT의 F1 점수가 매우 낮은 것은 고혈압 클래스에서 모델이 대부분의 예측을 **부정 클래스(0)**로만 하는 경향이 있을 수 있음을 나타냅니다.   \n",
    "\n",
    "AUC는 두 레이블 모두 좋은 값을 보여 주며, 이는 모델이 양성 클래스(1)에 대해 잘 구분할 수 있음을 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8ef621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 multi-label 지표\n",
    "y_true = np.stack([y_dm_test, y_ht_test], axis=1)\n",
    "y_pred_binary = np.stack([pred_dm_binary, pred_ht_binary], axis=1)\n",
    "\n",
    "print(\"📌 Hamming Loss:\", hamming_loss(y_true, y_pred_binary))\n",
    "print(\"📌 Exact Match Ratio:\", (y_true == y_pred_binary).all(axis=1).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f8d272",
   "metadata": {},
   "source": [
    "- Hamming Loss: 0.0752 ::: 다중 라벨 분류에서 잘못 예측된 라벨의 비율   :: 7.5% 잘못예측\n",
    "- Exact Match Ratio: 0.866 :: 예측한 모든 라벨이 정확히 정답과 일치한 샘플의 비율 :: 86.6%정도 두 타켓을 모두 정확히 맞춤   \n",
    "\n",
    "| 지표                    | 값               | 해석 요약                             |\n",
    "|-------------------------|------------------|----------------------------------------|\n",
    "| **Hamming Loss**        | 0.0752           | 잘못 예측한 라벨이 전체의 7.5%         |\n",
    "| **Exact Match Ratio**   | 0.8663           | 두 라벨 모두 정확히 맞춘 샘플 비율 86.6% |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87940b1",
   "metadata": {},
   "source": [
    "> ## setp04 : 모델 비교 및 결과 분석   \n",
    "> - Multi-task 모델 vs. 개별 Binary Classifier 비교\n",
    "> - confusion matrix, ROC curve 등 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a1e055",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score,f1_score, roc_auc_score,hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f73b65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## single label\n",
    "# 데이터 확인\n",
    "data = pd.read_csv(\"./Data_01_imputed_result.csv\")\n",
    "df = data.copy()\n",
    "\n",
    "# 입력/타겟 변수 ::::::::::: single label target = Target_DM\n",
    "X = df.drop(columns=['Target_DM', 'Target_HT']).values  # 입력값\n",
    "y = data[['Target_DM']].values\n",
    "\n",
    "# 학습/테스트 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73f345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from impute_model import *\n",
    "\n",
    "classifier = SingleLabelClassifier(input_dim = X_train.shape[1])\n",
    "classifier.model_train_fixed_hyperparameter(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfe567d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, roc_auc_score,\n",
    "    confusion_matrix, classification_report,\n",
    "    roc_curve, precision_recall_curve\n",
    ")\n",
    "\n",
    "def evaluate_single_label_model_with_plots(model, X_test, y_test):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # 입력 텐서\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test_tensor)\n",
    "        outputs = outputs.squeeze().cpu().numpy()\n",
    "\n",
    "    preds_binary = (outputs >= 0.5).astype(int)\n",
    "    y_true = y_test.ravel()\n",
    "\n",
    "    # 평가 지표 출력\n",
    "    print(\"📌 Accuracy:\", accuracy_score(y_true, preds_binary))\n",
    "    print(\"📌 F1 Score:\", f1_score(y_true, preds_binary))\n",
    "    print(\"📌 AUC:\", roc_auc_score(y_true, outputs))\n",
    "    print(\"\\n📋 Classification Report:\")\n",
    "    print(classification_report(y_true, preds_binary, digits=4))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, preds_binary)\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(\"🔹 Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_true, outputs)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f\"AUC = {roc_auc_score(y_true, outputs):.4f}\")\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.title(\"🔸 ROC Curve\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Precision-Recall Curve\n",
    "    precision, recall, _ = precision_recall_curve(y_true, outputs)\n",
    "    plt.figure()\n",
    "    plt.plot(recall, precision)\n",
    "    plt.title(\"🟢 Precision-Recall Curve\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return preds_binary, outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2e41cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_binary, preds_prob = evaluate_single_label_model_with_plots(classifier, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fafb7e0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551a02e3",
   "metadata": {},
   "source": [
    "### 🔍 Multi-task vs Single-label 성능 비교\n",
    "\n",
    "| 지표                   | Multi-task 결과                     | Single-label (DM만) 결과         |\n",
    "|------------------------|--------------------------------------|----------------------------------|\n",
    "| **Accuracy**           | 95.67% (DM), 89.29% (HT)             | **95.42%** (DM)                  |\n",
    "| **F1 Score**           | 0.16 (DM), 0.005 (HT)                | **0.2591** (DM)                  |\n",
    "| **ROC AUC**            | 0.886 (DM), 0.872 (HT)               | **0.8803** (DM)                  |\n",
    "| **Hamming Loss**       | 0.075                                | 해당 없음                        |\n",
    "| **Exact Match Ratio**  | 0.866                                | 해당 없음                        |\n",
    "\n",
    "---\n",
    "\n",
    "### 📊 성능 비교 요약\n",
    "\n",
    "#### ✅ Accuracy\n",
    "- **Multi-task(DM)**: ███████████████████▊ 95.67%\n",
    "- **Single-label(DM)**: ██████████████████▋ 95.42%\n",
    "\n",
    "#### 🎯 F1 Score\n",
    "- **Multi-task(DM)**: ███▍ 0.16\n",
    "- **Single-label(DM)**: ██████▌ 0.259\n",
    "\n",
    "#### 🧠 ROC AUC\n",
    "- **Multi-task(DM)**: █████████████████ 0.886\n",
    "- **Single-label(DM)**: ███████████████▉ 0.880\n",
    "\n",
    "---\n",
    "\n",
    "### 📌 해석 및 분석\n",
    "\n",
    "- **Accuracy**는 두 모델 모두 높은 편으로, Single-label 분류가 약간 더 낮지만 비슷한 수준입니다.\n",
    "- **F1 Score**에서는 Single-label 모델이 Multi-task보다 훨씬 우수하며, 특히 Positive 클래스(1.0)의 비율이 적은 불균형 데이터에서 중요한 지표입니다.\n",
    "- **ROC AUC**는 두 모델 모두 양호하지만 Multi-task가 약간 더 높습니다.\n",
    "- **Multi-task 모델**은 두 질병(DM, HT)을 동시에 예측하는 복합 모델로, 전체적인 예측 효율성과 다목적 활용에 유리합니다.\n",
    "- 반면 **Single-label 모델**은 특정 질병(DM)에 대해서 더 정밀하게 예측하는 데 강점을 보입니다.\n",
    "\n",
    "---\n",
    "\n",
    "> 💡 **결론**: 다중 질병 예측이 필요한 상황에서는 Multi-task 모델이 유용하며, 단일 질병 예측의 정밀도를 높이고 싶다면 Single-label 모델을 병행 활용하는 것도 좋은 전략입니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a88d94",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d6b2f4",
   "metadata": {},
   "source": [
    "---\n",
    "## **📊 Flow2**   \n",
    "> step01 : 문제 정의 및 흐름      \n",
    "   #   \n",
    "> setp02 : dataprocessing   \n",
    "   #\n",
    "> setp03 : 모델 설계& 모델 학습   \n",
    "> - 회귀 모델\n",
    "   #\n",
    "> setp04 : 모델 평가 및 결과 분석   \n",
    "   #\n",
    "> setp05 : 모델 튜닝 및 최적화   \n",
    "> - 하이퍼파라미터 튜닝, 교차 검증\n",
    "   #\n",
    "> setp06 : 정리 \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee39373",
   "metadata": {},
   "source": [
    "## step01 : 문제 정의 및 흐름\n",
    "목표 : 기존 데이터(Data_01_imputed_result.csv)를 사용하여 **나이(AGE)**를 예측하는 모델을 구축\n",
    "\n",
    "> 나이(AGE) 변수\n",
    "> - **AGE 변수**는 연속적인 값 ::**회귀 문제**\n",
    "\n",
    "#### 핵심 변경사항\n",
    "- **출력층**: 기존의 분류 문제에서는 각 클래스에 대해 확률을 출력하는 방식이었으나, 이번에는 나이라는 **연속적인 값을 예측**하므로 출력층은 **Linear**로 변경\n",
    "- **손실 함수**: 분류 문제에서 사용했던 `BCELoss` 대신 **회귀 손실 함수**인 `MSELoss` 또는 `MAELoss`를 사용.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d697c76e",
   "metadata": {},
   "source": [
    "## step02 : data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "353be723",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score,f1_score, roc_auc_score,hamming_loss\n",
    "\n",
    "# 데이터 확인\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"./Data_01_imputed_result.csv\")\n",
    "\n",
    "# # # 입력/타겟 변수\n",
    "# X = df.drop(columns=['AGE']).values  # 입력값\n",
    "# y = data[['AGE']].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18d93d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 나이값 데이터 상태 확인   ::: 로그변환 + 정규화\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# AGE 변수의 분포 확인\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# 히스토그램\n",
    "sns.histplot(data['AGE'], kde=True, bins=30, color='skyblue', stat='density', linewidth=0)\n",
    "plt.title('AGE Distribution with Histogram and KDE')\n",
    "plt.xlabel('AGE')\n",
    "plt.ylabel('Density')\n",
    "\n",
    "# 그래프 출력\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2648323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data['AGE_log'] = np.log1p(data['AGE'])  # log(AGE + 1) 변환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "113e4561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 확인\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"./Data_01_imputed_result.csv\")\n",
    "\n",
    "# 타켓 변수 스케일링 1차\n",
    "data['AGE_log'] = np.log1p(data['AGE'])  # log(AGE + 1) 변환\n",
    "\n",
    "# # # 입력/타겟 변수\n",
    "X = data.drop(columns=['AGE','AGE_log']).values  # 입력값\n",
    "y = data[['AGE_log']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "454a23f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 입력 변수 X 스케일링\n",
    "scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)  # X는 입력값을 스케일링\n",
    "\n",
    "# 타겟 변수 y 스케일링\n",
    "scaler_y = StandardScaler()\n",
    "y_scaled = scaler_y.fit_transform(y)  # y는 타겟값을 스케일링\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84064b5a",
   "metadata": {},
   "source": [
    "## setp03 : 모델 설계& 모델 학습   \n",
    "- 회귀 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24d80bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.2080\n",
      "Epoch [11/100], Loss: 0.2394\n",
      "Epoch [21/100], Loss: 0.2004\n",
      "Epoch [31/100], Loss: 0.2301\n",
      "Epoch [41/100], Loss: 0.1545\n",
      "Epoch [51/100], Loss: 0.2525\n",
      "Epoch [61/100], Loss: 0.2517\n",
      "Epoch [71/100], Loss: 0.2153\n",
      "Epoch [81/100], Loss: 0.1917\n",
      "Epoch [91/100], Loss: 0.2814\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "from impute_model import *\n",
    "model = AgeRegressor(input_dim=X_scaled.shape[1])\n",
    "model.model_train(X_train, y_train, num_epochs=100, batch_size=64, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e1c57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Performance on Test Set:\n",
      "🔹 MSE : 0.033477003979848007\n",
      "🔹 MAE : 0.14309418376580418\n",
      "🔹 R²  : 0.7328205085662083\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터로 예측\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'  # gpu\n",
    "if device != 'cuda':\n",
    "    raise RuntimeError(\"CUDA device not available. Please check if a GPU is available.\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    y_pred_scaled = model(X_test_tensor).cpu().numpy()\n",
    "\n",
    "# 원래 스케일로 복원 :: 실수할 뻔 함\n",
    "y_test_original = scaler_y.inverse_transform(y_test)\n",
    "y_pred_original = scaler_y.inverse_transform(y_pred_scaled)\n",
    "\n",
    "# 평가 지표\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "print(\"📊 Performance on Test Set:\")\n",
    "print(\"🔹 MSE :\", mean_squared_error(y_test_original, y_pred_original))\n",
    "print(\"🔹 MAE :\", mean_absolute_error(y_test_original, y_pred_original))\n",
    "print(\"🔹 R²  :\", r2_score(y_test_original, y_pred_original))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524ddd59",
   "metadata": {},
   "source": [
    "## 📊 Performance on Test Set:\n",
    "\n",
    "| Metric | Value               | Interpretation                                          |\n",
    "|--------|---------------------|---------------------------------------------------------|\n",
    "| **MSE** | 0.0335              | **Mean Squared Error (MSE)**는 예측값과 실제값 간의 제곱 차이의 평균입니다. 이 값이 작을수록 모델의 예측 성능이 좋다는 의미입니다. 0.0335는 비교적 낮은 MSE 값으로, 모델이 예측을 잘 했음을 시사합니다. |\n",
    "| **MAE** | 0.1431              | **Mean Absolute Error (MAE)**는 예측값과 실제값 간의 절대 차이의 평균입니다. 0.1431은 예측값과 실제값 간 평균 차이가 약 0.143이라는 의미로, 낮을수록 정확한 예측을 나타냅니다. |\n",
    "| **R²**  | 0.7328              | **R² (결정계수)**는 모델이 데이터를 얼마나 잘 설명하는지를 나타내는 지표입니다. 0.7328은 약 73% 정도의 설명력을 가진 모델임을 의미합니다. 즉, 모델이 데이터를 잘 적합시켰다고 해석할 수 있습니다. |\n",
    "\n",
    "### 종합적인 해석:\n",
    "- **MSE**와 **MAE** 값이 모두 작기 때문에 모델이 예측을 잘 수행했다는 것을 알 수 있습니다.\n",
    "- **R²** 값이 0.73 정도로, 모델이 73%의 데이터 변동성을 설명할 수 있음을 나타냅니다. 이는 모델이 꽤 좋은 성능을 보였음을 의미합니다.\n",
    "\n",
    "따라서, 이 모델은 나이 예측에 있어 적당한 성능을 발휘한 것으로 볼 수 있습니다. 다만, 성능 개선을 위해 추가적인 하이퍼파라미터 튜닝이나 다른 모델을 실험할 수 있습니다.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dibk311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
