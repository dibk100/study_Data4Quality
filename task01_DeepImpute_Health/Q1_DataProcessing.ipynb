{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4980a134",
   "metadata": {},
   "source": [
    "# Q1. Data Processing\n",
    "\n",
    "Flow1. Í≤∞Ï∏°Ïπò ÎåÄÏ≤¥  \n",
    "Î®∏Ïã†Îü¨Îãù/Îî•Îü¨Îãù Í∏∞Î∞òÏùò Í≤∞Ï∏°Ïπò ÎåÄÏ≤¥ Î™®Îç∏ÏùÑ ÌôúÏö©ÌïòÏó¨ Í≤∞Ï∏°ÏπòÎ•º Ìö®Í≥ºÏ†ÅÏúºÎ°ú Î≥¥Í∞ÑÌïú ÌõÑ, Î∂ÑÎ•ò Î™®Îç∏ÏùÑ Í∞úÎ∞ú.\n",
    "\n",
    "Flow2. ÌÅ¥ÎûòÏä§ Î∂àÍ∑†Ìòï Î¨∏Ï†ú Ìï¥Í≤∞  \n",
    "ÎãπÎá®(Target_DM) Î∞è Í≥†ÌòàÏïï(Target_HT) Ïú†Î≥ëÏóê ÎåÄÌïú Í∞Å Î∂ÑÎ•ò Î™®Îç∏ÏùÑ ÎßåÎì§ Îïå ÌÅ¥ÎûòÏä§ Î∂àÍ∑†Ìòï Î¨∏Ï†úÎ•º Í≥†Î†§ÌïòÏó¨ Î™®Îç∏ ÏÑ±Îä•ÏùÑ Í∞úÏÑ†\n",
    "\n",
    "Ï†ÅÏö© Í∞ÄÎä•Ìïú Ï†ÑÎûµ\n",
    "\n",
    "| Ï†ÑÎûµ               | ÏÑ§Î™Ö                                                                 |\n",
    "|--------------------|----------------------------------------------------------------------|\n",
    "| **SMOTE**          | ÏÜåÏàò ÌÅ¥ÎûòÏä§ Îç∞Ïù¥ÌÑ∞Î•º Ìï©ÏÑ±ÌïòÏó¨ ÎäòÎ¶¨Îäî Ïò§Î≤ÑÏÉòÌîåÎßÅ Í∏∞Î≤ï                |\n",
    "| **Ïñ∏ÎçîÏÉòÌîåÎßÅ**     | Îã§Ïàò ÌÅ¥ÎûòÏä§ Îç∞Ïù¥ÌÑ∞Î•º Ï§ÑÏó¨ Í∑†ÌòïÏùÑ ÎßûÏ∂§                               |\n",
    "| **Class Weight**   | `class_weight='balanced'` ÏòµÏÖò Îì±ÏùÑ ÌÜµÌï¥ ÏûêÎèôÏúºÎ°ú Í∞ÄÏ§ëÏπòÎ•º Î∂ÄÏó¨     |\n",
    "| **ÏïôÏÉÅÎ∏î Í∏∞Î≤ï**    | Ïó¨Îü¨ Î™®Îç∏ÏùÑ Ï°∞Ìï©ÌïòÏó¨ ÌÅ¥ÎûòÏä§ Î∂àÍ∑†ÌòïÏùò ÏòÅÌñ•ÏùÑ Ï§ÑÏù¥Îäî Î∞©Î≤ï              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c589cffa",
   "metadata": {},
   "source": [
    "## Îç∞Ïù¥ÌÑ∞ ÌôïÏù∏\n",
    "- Í±¥Í∞ïÍ≤ÄÏßÑ Î∞è ÏÉùÏ≤¥ Ï†ïÎ≥¥ Îç∞Ïù¥ÌÑ∞ÏÖã   \n",
    "- 31 column   \n",
    "- ÏãúÍ≥ÑÏó¥ Îç∞Ïù¥ÌÑ∞X, Î≥ÄÏàòÎ≥Ñ Ïó∞Í¥ÄÏÑ±ÏùÄ ÏûàÏùÑ Í≤É Í∞ôÏùå."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21f26e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Îç∞Ïù¥ÌÑ∞ ÌôïÏù∏\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"./Data_01.csv\")\n",
    "\n",
    "# print(data.head())  # Îç∞Ïù¥ÌÑ∞ ÏùºÎ∂Ä Ï∂úÎ†•\n",
    "# print(data.info())  # Îç∞Ïù¥ÌÑ∞ Ï†ïÎ≥¥ Ï∂úÎ†•\n",
    "# print(data.describe())  # Îç∞Ïù¥ÌÑ∞ ÌÜµÍ≥Ñ Ï†ïÎ≥¥ Ï∂úÎ†•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ae1bba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target_DM\n",
      "0.0    19094\n",
      "1.0      881\n",
      "Name: count, dtype: int64\n",
      "Target_HT\n",
      "0.0    17888\n",
      "1.0     2087\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ÌÅ¥ÎûòÏä§ Î∂àÍ∑†Ìòï ÌôïÏù∏\n",
    "print(data['Target_DM'].value_counts())\n",
    "print(data['Target_HT'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baeea44",
   "metadata": {},
   "source": [
    "---\n",
    "## **üìä Flow1**   \n",
    "> step01 : Î≥ÄÏàòÎ≥Ñ Í≤∞Ï∏° ÏàòÏπò(ratio) ÌôïÏù∏   \n",
    "> - ÏôÑÏ†ÑÌûà Í≤∞Ï∏°Îêú colums data 3col Î∞úÍ≤¨ --> Ï†úÍ±∞   \n",
    "> - target colums : yÏóê Ìï¥ÎãπÌïòÎäî Ïª¨Îüº. --> Ìï¥Îãπ ÏπºÎüºÏóêÎèÑ 24Í∞ú Í≤∞Ï∏°Ïπò ÏûàÏùå. Ïö∞ÏÑ† Ìï¥Îãπ ÏûëÏóÖÏóêÏÑúÎäî drop\n",
    "   #   \n",
    "> setp02 : Autoencoder Í∞úÎ∞ú    \n",
    "> - hyperparameters Ïã§Ìóò\n",
    "> - Autoencoder Î™®Îç∏ ÌïôÏäµ\n",
    "  \n",
    "   #\n",
    "> setp03 : Î™®Îç∏ Í≤ÄÏ¶ù -> ÎÇ¥Í∞Ä Í∞úÎ∞úÌïú Î™®Îç∏Ïù¥ Í≤∞Ï∏°ÏπòÎ•º Ïûò ÎåÄÏ≤¥ÌñàÎäîÏßÄ Í≤ÄÏ¶ù   \n",
    "> BaselineÏúºÎ°ú MICE, KNN Îì± ÎπÑÍµê   \n",
    ">>   RMSE, MAE, R¬≤ ÏßÄÌëú ÌôúÏö©\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76620d2",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 01   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73f8ffd2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3060,
     "status": "ok",
     "timestamp": 1744169476372,
     "user": {
      "displayName": "ÍπÄÏàòÌòÑ",
      "userId": "13233624853538897734"
     },
     "user_tz": -540
    },
    "id": "73f8ffd2",
    "outputId": "0388f9eb-fca5-4284-8e0f-f21dd1c14ef9"
   },
   "outputs": [],
   "source": [
    "# ÏôÑÏ†ÑÌïú Í≤∞Ï∏°Ïπò Ï†úÍ±∞\n",
    "drop_cols = ['HE_Ucot', 'HE_FVC', 'HE_Frtn']\n",
    "df = data.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0899f3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Missing Count  Missing Ratio (%)\n",
      "HE_Bplt            11882          59.412971\n",
      "HE_USG              6941          34.706735\n",
      "HE_Uph              6941          34.706735\n",
      "HE_WBC              6759          33.796690\n",
      "HE_HbA1c            6189          30.946547\n",
      "HE_LDL              3122          15.610781\n",
      "HE_TG                333           1.665083\n",
      "HE_glu               330           1.650083\n",
      "HE_ALT               262           1.310066\n",
      "HE_AST               227           1.135057\n",
      "HE_HB                219           1.095055\n",
      "HE_HCT               215           1.075054\n",
      "HE_RBC               213           1.065053\n",
      "HE_BUN               213           1.065053\n",
      "HE_CHOL              212           1.060053\n",
      "HE_HDL               210           1.050053\n",
      "HE_CREA              187           0.935047\n",
      "HE_PLS               169           0.845042\n",
      "Target_DM             24           0.120006\n",
      "Target_HT             24           0.120006\n",
      "HE_WC                  4           0.020001\n"
     ]
    }
   ],
   "source": [
    "missing_count = df.isnull().sum()     # ÏπºÎüºÎ≥Ñ Í≤∞Ï∏°Ïπò Í∞úÏàò\n",
    "missing_ratio = df.isnull().mean() * 100\n",
    "\n",
    "# Î≥¥Í∏∞ Ï¢ãÍ≤å ÌïòÎÇòÏùò Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑÏúºÎ°ú Ï†ïÎ¶¨\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_count,\n",
    "    'Missing Ratio (%)': missing_ratio\n",
    "})\n",
    "\n",
    "# Í≤∞Ï∏°ÏπòÍ∞Ä ÏûàÎäî Î≥ÄÏàòÎßå ÌïÑÌÑ∞ÎßÅ \n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0]\n",
    "\n",
    "# Í≤∞Ï∏°Ïπò ÎßéÏùÄ ÏàúÏúºÎ°ú Ï†ïÎ†¨\n",
    "missing_df = missing_df.sort_values(by='Missing Count', ascending=False)\n",
    "\n",
    "print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0d5f5ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>HE_WT</th>\n",
       "      <th>HE_HT</th>\n",
       "      <th>HE_WC</th>\n",
       "      <th>HE_BMI</th>\n",
       "      <th>HE_SBP</th>\n",
       "      <th>HE_DBP</th>\n",
       "      <th>HE_PLS</th>\n",
       "      <th>HE_Uph</th>\n",
       "      <th>...</th>\n",
       "      <th>HE_AST</th>\n",
       "      <th>HE_ALT</th>\n",
       "      <th>HE_CHOL</th>\n",
       "      <th>HE_TG</th>\n",
       "      <th>HE_HDL</th>\n",
       "      <th>HE_LDL</th>\n",
       "      <th>HE_glu</th>\n",
       "      <th>HE_HbA1c</th>\n",
       "      <th>HE_BUN</th>\n",
       "      <th>HE_CREA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>64.24</td>\n",
       "      <td>157.8</td>\n",
       "      <td>96.8</td>\n",
       "      <td>25.798326</td>\n",
       "      <td>152.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>159.4</td>\n",
       "      <td>261.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>78.24</td>\n",
       "      <td>169.5</td>\n",
       "      <td>92.2</td>\n",
       "      <td>27.232621</td>\n",
       "      <td>111.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>196.4</td>\n",
       "      <td>69.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>53.60</td>\n",
       "      <td>150.7</td>\n",
       "      <td>69.3</td>\n",
       "      <td>23.601428</td>\n",
       "      <td>118.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>82.6</td>\n",
       "      <td>95.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>59.56</td>\n",
       "      <td>154.3</td>\n",
       "      <td>78.8</td>\n",
       "      <td>25.016286</td>\n",
       "      <td>116.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>62.2</td>\n",
       "      <td>94.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>57.70</td>\n",
       "      <td>146.2</td>\n",
       "      <td>89.2</td>\n",
       "      <td>26.994859</td>\n",
       "      <td>155.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>53.00</td>\n",
       "      <td>161.5</td>\n",
       "      <td>72.9</td>\n",
       "      <td>20.320333</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>92.4</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>61.10</td>\n",
       "      <td>163.5</td>\n",
       "      <td>78.5</td>\n",
       "      <td>22.856288</td>\n",
       "      <td>103.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>79.4</td>\n",
       "      <td>89.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>65.50</td>\n",
       "      <td>151.0</td>\n",
       "      <td>90.5</td>\n",
       "      <td>28.726810</td>\n",
       "      <td>140.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>141.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>72.60</td>\n",
       "      <td>165.0</td>\n",
       "      <td>90.5</td>\n",
       "      <td>26.666667</td>\n",
       "      <td>119.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>124.8</td>\n",
       "      <td>107.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>66.50</td>\n",
       "      <td>155.4</td>\n",
       "      <td>90.8</td>\n",
       "      <td>27.537190</td>\n",
       "      <td>111.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>125.4</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19975 rows √ó 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SEX  AGE  HE_WT  HE_HT  HE_WC     HE_BMI  HE_SBP  HE_DBP  HE_PLS  \\\n",
       "0        2   50  64.24  157.8   96.8  25.798326   152.0    86.0    17.0   \n",
       "1        1   32  78.24  169.5   92.2  27.232621   111.0    71.0    20.0   \n",
       "2        2   31  53.60  150.7   69.3  23.601428   118.0    68.0    21.0   \n",
       "3        2   32  59.56  154.3   78.8  25.016286   116.0    83.0    18.0   \n",
       "4        2   67  57.70  146.2   89.2  26.994859   155.0    95.0    17.0   \n",
       "...    ...  ...    ...    ...    ...        ...     ...     ...     ...   \n",
       "19994    1   34  53.00  161.5   72.9  20.320333   121.0    81.0    17.0   \n",
       "19995    2   29  61.10  163.5   78.5  22.856288   103.0    72.0    16.0   \n",
       "19996    2   61  65.50  151.0   90.5  28.726810   140.0    81.0    15.0   \n",
       "19997    1   57  72.60  165.0   90.5  26.666667   119.0    80.0    20.0   \n",
       "19998    2   54  66.50  155.4   90.8  27.537190   111.0    81.0    15.0   \n",
       "\n",
       "       HE_Uph  ...  HE_AST  HE_ALT  HE_CHOL  HE_TG  HE_HDL  HE_LDL  HE_glu  \\\n",
       "0         6.0  ...    27.0    27.0    229.0  113.0    47.0   159.4   261.0   \n",
       "1         5.0  ...    30.0    27.0    274.0  173.0    43.0   196.4    69.0   \n",
       "2         5.0  ...    15.0    15.0    163.0   82.0    64.0    82.6    95.0   \n",
       "3         5.0  ...    20.0    12.0    145.0   64.0    70.0    62.2    94.0   \n",
       "4         6.5  ...    28.0    21.0    171.0   85.0    51.0   103.0   122.0   \n",
       "...       ...  ...     ...     ...      ...    ...     ...     ...     ...   \n",
       "19994     6.5  ...    24.0    18.0    160.0   98.0    48.0    92.4    86.0   \n",
       "19995     5.0  ...    16.0    12.0    151.0  213.0    29.0    79.4    89.0   \n",
       "19996     5.5  ...    16.0    13.0    245.0  593.0    28.0     NaN   141.0   \n",
       "19997     5.0  ...    21.0    25.0    188.0   56.0    52.0   124.8   107.0   \n",
       "19998     5.5  ...    19.0    23.0    172.0   53.0    36.0   125.4    87.0   \n",
       "\n",
       "       HE_HbA1c  HE_BUN  HE_CREA  \n",
       "0          10.3    14.0      0.8  \n",
       "1           4.0    19.0      1.1  \n",
       "2           5.0    10.0      0.8  \n",
       "3           4.5    11.0      0.8  \n",
       "4           5.5    15.0      0.9  \n",
       "...         ...     ...      ...  \n",
       "19994       NaN     9.8      1.0  \n",
       "19995       NaN     8.7      0.9  \n",
       "19996       7.8    18.6      0.8  \n",
       "19997       NaN    25.9      1.0  \n",
       "19998       NaN    14.5      0.7  \n",
       "\n",
       "[19975 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ÌÉÄÍ≤ü Î≥ÄÏàò Î∂ÑÎ¶¨\n",
    "target_cols = ['Target_DM', 'Target_HT']\n",
    "\n",
    "# ÌÉÄÍ≤üÍ∞íÏù¥ NULL 24Í∞úÎäî Ï†úÍ±∞\n",
    "df = df.dropna(subset=['Target_DM','Target_HT'])                    # 24Í∞ú NaNÎç∞Ïù¥ÌÑ∞Îì§ÏùÄ ÏÇ≠Ï†ú \n",
    "features = df.drop(columns=target_cols)\n",
    "targets = df[target_cols]\n",
    "\n",
    "\n",
    "# featuresÎ°úÎßå Í≤∞Ï∏°Ïπò ÎåÄÏ≤¥Ìï¥Î≥¥Í∏∞\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5244c981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Í≤∞Ï∏° ÎßàÏä§ÌÅ¨ Ï†ÄÏû• : featuresÏóêÏÑú Í≤∞Ï∏°ÏπòÍ∞Ä ÏûàÎäî ÏúÑÏπòÎ•º maskÎùºÎäî Î≥ÄÏàòÏóê Î∞îÏù¥ÎÑàÎ¶¨Í∞íÏúºÎ°ú Ï†ÄÏû•. --> maskÍ∞íÏù¥ TrueÏù∏ Í∞íÏùÑ Îî•Îü¨ÎãùÏùÑ ÌÜµÌï¥ ÏòàÏ∏°ÌïòÏó¨ Íµ¨ÌòÑÌï† Í≤É\n",
    "mask = features.isnull()\n",
    "\n",
    "# ÏûÑÏãú Í≤∞Ï∏°Ïπò ÎåÄÏ≤¥ (Ïª¨Îüº ÌèâÍ∑†ÏúºÎ°ú)\n",
    "features_filled = features.fillna(features.mean())\n",
    "\n",
    "# Ïä§ÏºÄÏùºÎßÅ\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edb97ab",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 02: Îî•Îü¨Îãù Í∏∞Î∞ò Î™®Îç∏Î°ú Í≤∞Ï∏°Ïπò ÎåÄÏ≤¥ÌïòÍ∏∞   \n",
    "   #\n",
    "### ‚úÖ Autoencoder Í∏∞Î∞ò Imputer\n",
    "ÏûÖÎ†• Îç∞Ïù¥ÌÑ∞Î•º ÏïïÏ∂ïÌïòÍ≥† Îã§Ïãú Î≥µÏõêÌïòÎäî Íµ¨Ï°∞Î•º ÌÜµÌï¥ Í≤∞Ï∏°ÏπòÎ•º ÏòàÏ∏°\n",
    "><details>\n",
    "><summary>‚ö†Ô∏è test Experiment: Baseline Dense Autoencoder</summary>\n",
    ">\n",
    ">- **Ïã§Ìóò Î™®Îç∏**: Îã®Ïàú Dense Íµ¨Ï°∞Ïùò Autoencoder(layers 4)  \n",
    ">- **Í≤∞Í≥º**: ÌèâÍ∑†ÏúºÎ°ú ÎåÄÏ≤¥Ìïú Í∞íÍ≥º ÌÅ∞ Ï∞®Ïù¥Í∞Ä ÏóÜÏóàÏùå. Îã®Ïàú ÌèâÍ∑† Î≥µÏõê ÌòïÌÉúÎ°ú Í≤∞Í≥º ÎèÑÏ∂úÎê®.\n",
    ">\n",
    "><details>\n",
    "><summary>üîç Ïã§Ìóò ÌùêÎ¶Ñ Î∞è ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÌäúÎãù </summary>\n",
    ">\n",
    ">- **ÌååÏùº**: `search_hyperparameters.py`  \n",
    ">- **Î™©Ï†Å**: Autoencoder ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÏµúÏ†ÅÌôî  \n",
    ">- **ÏÜåÏöî ÏãúÍ∞Ñ**: ÏïΩ 1ÏãúÍ∞Ñ 30Î∂Ñ, Ï¥ù 90 Ï°∞Ìï© Ïã§Ìóò  \n",
    ">\n",
    ">**Best Hyperparameters**\n",
    ">- `batch_size`: 64  \n",
    ">- `epochs`: 50  \n",
    ">- `learning_rate`: 0.0005  \n",
    ">- `optimizer`: Adam  \n",
    ">\n",
    "></details>\n",
    "></details>\n",
    "   #\n",
    "   #\n",
    "   #\n",
    "   #\n",
    "#### üß™**Experiment: Denoising Autoencoder (DAE)**\n",
    "- ÏõêÎ¶¨: Îç∞Ïù¥ÌÑ∞Ïóê ÏùòÎèÑÏ†ÅÏúºÎ°ú ÎÖ∏Ïù¥Ï¶àÎ•º Ï∂îÍ∞ÄÌïòÏó¨ Î™®Îç∏Ïù¥ Î≥µÏõêÎ†•ÏùÑ ÌïôÏäµÌïòÍ≤å ÎßåÎì¨\n",
    ">**Best Hyperparameters**\n",
    ">- `batch_size`: 128  \n",
    ">- `epochs`: 80  \n",
    ">- `learning_rate`: 0.005  \n",
    ">- `optimizer`: Adam  \n",
    ">- `noise_level`: 0.1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bdd0953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from impute_model import DenoisingAutoencoder\n",
    "from utils import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ÌÖêÏÑúÌòïÌÉúÎ°ú Î≥ÄÌôò\n",
    "X_tensor = torch.tensor(features_scaled, dtype=torch.float32)\n",
    "rows=X_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db8ef621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################### Train! #######################\n",
      "Epoch 1/80 - Loss: 78.2925\n",
      "Epoch 11/80 - Loss: 7.1963\n",
      "Epoch 21/80 - Loss: 5.0457\n",
      "Epoch 31/80 - Loss: 5.0693\n",
      "Epoch 41/80 - Loss: 3.9808\n",
      "Epoch 51/80 - Loss: 2.3668\n",
      "Epoch 61/80 - Loss: 3.2009\n",
      "Epoch 71/80 - Loss: 2.3749\n",
      "> Final ::: Epoch 80/80 - Loss: 1.7836\n",
      "\n",
      "> Ï¥ù Ïã§Ìñâ ÏãúÍ∞Ñ: 63.44Ï¥à\n"
     ]
    }
   ],
   "source": [
    "# step02 : Î™®Îç∏ Ïã§Ìóò.\n",
    "\n",
    "###### setting : hyperparameters Í≥†Ï†ï, Î™®Îç∏ÏùÄ Autoencoder\n",
    "model = DenoisingAutoencoder(input_dim=rows,noise_factor=0.1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)      # Adam, 0.001, 40\n",
    "epochs = 80\n",
    "batch_size = 128\n",
    "\n",
    "train_X, test_X = dataset_split(features_scaled)\n",
    "train_loader, test_loader = loader_dataset(train_X,test_X,batch_size)\n",
    "\n",
    "# training\n",
    "model.model_train_fixed_hyperparameter(train_loader,optimizer,epochs)\n",
    "\n",
    "# Î™®Îç∏ Ï†ÄÏû•\n",
    "torch.save(model.state_dict(), \"denoisingAutoencoder_model_test.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66bee921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step03 : modelÎ°ú Í≤∞Ï∏°Í∞í ÏòàÏ∏° : predicted_values\n",
    "\n",
    "# # # Ï†ÄÏû•ÌñàÎçò Î™®Îç∏ Î∂ÄÎ•¥Í∏∞\n",
    "# model = DenoisingAutoencoder(input_dim=rows)\n",
    "# model.load_state_dict(torch.load(\"denoisingAutoencoder_model_test.pth\"))\n",
    "\n",
    "def predictMyModel(model, X_tensor, device='cuda'):\n",
    "\n",
    "    model.eval()  # ÌèâÍ∞Ä Î™®ÎìúÎ°ú ÏÑ§Ï†ï\n",
    "    device = device if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    with torch.no_grad():\n",
    "        X_tensor = X_tensor.to(device)  \n",
    "        predicted_values = model(X_tensor).detach().cpu().numpy() \n",
    "\n",
    "    return predicted_values\n",
    "\n",
    "predicted_values = predictMyModel(model,X_tensor)\n",
    "\n",
    "assert predicted_values.shape == features_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94ae85b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step04-2 : Î≥µÏõêÌïòÍ∏∞\n",
    "X_final = replace_missing_values(features_scaled,mask,predicted_values,scaler)\n",
    "\n",
    "# Ïó≠Ïä§ÏºÄÏùºÎßÅ\n",
    "X_final = scaler.inverse_transform(X_final)\n",
    "df_imputed = pd.DataFrame(X_final, columns=features.columns)\n",
    "df_result = pd.concat([df_imputed, targets.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Ï†ÄÏû•\n",
    "df_result.to_csv(\"Data_01_imputed_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6fe9677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Í≤∞Ï∏°Í∞í :  nan\n",
      "# ÏûÑÏùòÎ°ú ÌèâÍ∑†Í∞í ÎåÄÏ≤¥ :  23.92620426265862\n",
      "# autoencoder ÎåÄÏ≤¥Í∞í :  24.392927712007527\n"
     ]
    }
   ],
   "source": [
    "## ÌôïÏù∏ÌïòÍ∏∞\n",
    "print('# Í≤∞Ï∏°Í∞í : ',data['HE_Bplt'][19972])\n",
    "print('# ÏûÑÏùòÎ°ú ÌèâÍ∑†Í∞í ÎåÄÏ≤¥ : ',features_filled['HE_Bplt'][19972])\n",
    "print('# autoencoder ÎåÄÏ≤¥Í∞í : ',df_result['HE_Bplt'][19972])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4a859c",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 03: Î™®Îç∏ Í≤ÄÏ¶ù  \n",
    "   #\n",
    "### ‚úÖ step03-01 : Î≥µÏõê ÏÑ±Îä• Í≤ÄÏ¶ù\n",
    "\n",
    "- Î™©Ï†Å: Autoencoder Í∏∞Î∞ò Í≤∞Ï∏°Ïπò ÎåÄÏ≤¥ ÏÑ±Îä•ÏùÑ Í∏∞Ï°¥ Í∏∞Î≤ïÎì§Í≥º **Ï†ïÎüâÏ†ÅÏúºÎ°ú ÎπÑÍµê ÌèâÍ∞Ä**\n",
    ">> Í≤∞Ï∏°ÏπòÍ∞Ä ÏóÜÎçò Îç∞Ïù¥ÌÑ∞Î•º ÎåÄÏÉÅÏúºÎ°ú reconstruction ÏÑ±Îä•ÏùÑ ÌèâÍ∞Ä\n",
    "><details>\n",
    "><summary>üìä ÏÇ¨Ïö©Îêú ÌèâÍ∞Ä ÏßÄÌëú\n",
    ">\n",
    ">- **RMSE** (Root Mean Squared Error)  \n",
    ">- **MAE** (Mean Absolute Error)  \n",
    ">- **R¬≤ Score** (Í≤∞Ï†ïÍ≥ÑÏàò)  \n",
    ">\n",
    "></details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0def9fdf",
   "metadata": {},
   "source": [
    "### ‚úÖ step03-02 : Î≥µÏõê Îç∞Ïù¥ÌÑ∞ Í∏∞Î∞ò Î∂ÑÎ•ò Î™®Îç∏ ÏÑ±Îä• Í≤ÄÏ¶ù\n",
    "\n",
    "><details>\n",
    "><summary>‚öñÔ∏è Baseline: MICE, KNN vs Autoencoder\n",
    ">\n",
    ">Î™®Îì† Î∞©Î≤ïÏùÄ ÎèôÏùºÌïú Ï°∞Í±¥ ÌïòÏóêÏÑú Î∂ÑÎ•ò Î™®Îç∏ÏùÑ ÌïôÏäµÌïòÏó¨ ÏÑ±Îä•ÏùÑ ÎπÑÍµêÌï®.\n",
    ">\n",
    ">**Ïã§Ìóò ÎπÑÍµê Î∞©Ïãù**\n",
    ">\n",
    ">1. ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞Ïùò Í≤∞Ï∏°Ïπò ‚Üí **MICE**Î°ú ÎåÄÏ≤¥ ‚Üí Î∂ÑÎ•ò Î™®Îç∏ Ï†ÅÏö© ‚Üí ÏÑ±Îä• Í∏∞Î°ù  \n",
    ">2. ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞Ïùò Í≤∞Ï∏°Ïπò ‚Üí **KNN**ÏúºÎ°ú ÎåÄÏ≤¥ ‚Üí Î∂ÑÎ•ò Î™®Îç∏ Ï†ÅÏö© ‚Üí ÏÑ±Îä• Í∏∞Î°ù  \n",
    ">3. ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞Ïùò Í≤∞Ï∏°Ïπò ‚Üí **Autoencoder**Î°ú ÎåÄÏ≤¥ ‚Üí Î∂ÑÎ•ò Î™®Îç∏ Ï†ÅÏö© ‚Üí ÏÑ±Îä• Í∏∞Î°ù  \n",
    ">\n",
    "></details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c066c3",
   "metadata": {},
   "source": [
    "---\n",
    "### ‚úÖ step03-01 : Î≥µÏõê ÏÑ±Îä• Í≤ÄÏ¶ù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "809be9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.impute import KNNImputer\n",
    "import numpy as np\n",
    "from impyute.imputation.cs import mice\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# ÏÑ±Îä• ÌèâÍ∞Ä Ìï®Ïàò\n",
    "def evaluate_model(actual_values, imputed_values):\n",
    "    rmse = np.sqrt(mean_squared_error(actual_values, imputed_values))\n",
    "    mae = mean_absolute_error(actual_values, imputed_values)\n",
    "    r2 = r2_score(actual_values, imputed_values)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "# 3. MICE Î™®Îç∏ (impyute)\n",
    "def impute_mice(data):\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    imputed_data = imputer.fit_transform(data)\n",
    "    return imputed_data\n",
    "\n",
    "# 4. KNN Î™®Îç∏\n",
    "def impute_knn(data):\n",
    "    imputer = SimpleImputer(strategy='most_frequent')\n",
    "    imputed_data = imputer.fit_transform(data)\n",
    "    return imputed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261e5c46",
   "metadata": {},
   "source": [
    "Í≤∞Ï∏°ÏπòÍ∞Ä ÏóÜÎäî ÏôÑÏ†ÑÌïú Ìñâ(rows) Ï§ÄÎπÑÌïòÍ∏∞   \n",
    "> 7042Í∞ú"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bff2694c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7042, 26)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Í≤∞Ï∏°ÏπòÍ∞Ä ÏóÜÎäî ÏôÑÏ†ÑÌïú Ìñâ(rows) Ï§ÄÎπÑÌïòÍ∏∞\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"./Data_01.csv\")\n",
    "\n",
    "# Í≤∞Ï∏°Ïπò Î≥ÄÏàò Î∞è ÌÉÄÍ≤üÍ∞í Ï†úÍ±∞\n",
    "drop_cols = ['HE_Ucot', 'HE_FVC', 'HE_Frtn','Target_DM','Target_HT']\n",
    "df = data.drop(columns=drop_cols)\n",
    "\n",
    "# Í≤∞Ï∏°ÏπòÍ∞Ä ÏûàÎäî Ìñâ Ï†ÑÏ≤¥ ÏÇ≠Ï†ú\n",
    "actual_values = df.dropna()\n",
    "\n",
    "actual_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab34b5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ïä§ÏºÄÏùºÎßÅ\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_e = StandardScaler()\n",
    "actual_values_scaled = scaler.fit_transform(actual_values)\n",
    "\n",
    "# \n",
    "actual_tensor = torch.tensor(actual_values_scaled, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8fccc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Í≤∞Ï∏°Ïπò ÎåÄÏ≤¥\n",
    "\n",
    "autoencoder_imputed = predictMyModel(model,actual_tensor)\n",
    "mice_imputed = impute_mice(actual_values_scaled)\n",
    "knn_imputed = impute_knn(actual_values_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e43fab35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder Î™®Îç∏ ÏÑ±Îä•:\n",
      "RMSE: 76.5261106124488, MAE: 52.34363555908203, R¬≤: -201.62091064453125\n",
      "\n",
      "MICE Î™®Îç∏ ÏÑ±Îä•:\n",
      "RMSE: 76.52320944703268, MAE: 52.34628014045013, R¬≤: -211.06590165250128\n",
      "\n",
      "KNN Î™®Îç∏ ÏÑ±Îä•:\n",
      "RMSE: 76.52320944703268, MAE: 52.34628014045013, R¬≤: -211.06590165250128\n"
     ]
    }
   ],
   "source": [
    "# ÌèâÍ∞Ä\n",
    "rmse_autoencoder, mae_autoencoder, r2_autoencoder = evaluate_model(actual_values, autoencoder_imputed)\n",
    "rmse_mice, mae_mice, r2_mice = evaluate_model(actual_values, mice_imputed)\n",
    "rmse_knn, mae_knn, r2_knn = evaluate_model(actual_values, knn_imputed)\n",
    "\n",
    "# Í≤∞Í≥º Ï∂úÎ†•\n",
    "print(\"Autoencoder Î™®Îç∏ ÏÑ±Îä•:\")\n",
    "print(f\"RMSE: {rmse_autoencoder}, MAE: {mae_autoencoder}, R¬≤: {r2_autoencoder}\")\n",
    "\n",
    "print(\"\\nMICE Î™®Îç∏ ÏÑ±Îä•:\")\n",
    "print(f\"RMSE: {rmse_mice}, MAE: {mae_mice}, R¬≤: {r2_mice}\")\n",
    "\n",
    "print(\"\\nKNN Î™®Îç∏ ÏÑ±Îä•:\")\n",
    "print(f\"RMSE: {rmse_knn}, MAE: {mae_knn}, R¬≤: {r2_knn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd77739",
   "metadata": {},
   "source": [
    "Í≤∞Í≥º:   \n",
    "- ÏÑ∏ Î™®Îç∏Ïùò ÏÑ±Îä•ÏùÄ ÎπÑÏä∑Ìï®. R2Í∞íÏù¥ -211Ïù¥ÏÉÅÏù¥ÎØÄÎ°ú ÌèâÍ∑†Í∞í ÏòàÏ∏°Î≥¥Îã§ Î™ªÌïú Í≤∞Í≥º   \n",
    "> ÏõêÏù∏ Ï∂îÏ∏°1 : Í≤∞Ï∏°Ïπò ÎåÄÏ≤¥ ÌõÑ ÌíàÏßàÏù¥ ÎÇÆÏïÑÏßê   \n",
    "> ÏõêÏù∏ Ï∂îÏ∏°2 : ÌèâÍ∞Ä ÏßÄÌëú Í≥ÑÏÇ∞ Î∞©Ïãù Î¨∏Ï†ú   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09563b4d",
   "metadata": {},
   "source": [
    "---\n",
    "### ‚úÖ step03-02 : Î≥µÏõê Îç∞Ïù¥ÌÑ∞ Í∏∞Î∞ò **Î∂ÑÎ•ò Î™®Îç∏ ÏÑ±Îä• Í≤ÄÏ¶ù**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdd4395e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"./Data_01.csv\")\n",
    "\n",
    "# 'Target_DM'Î•º Ïûò ÏòàÏ∏°ÌïòÎäîÏßÄ Í≤ÄÏ¶ùÌïòÎ†§Í≥† Ìï®. :: ÌÉÄÏºì ÏûêÏ≤¥Ïóê NanÏù∏ Í≤ΩÏö∞Í∞Ä ÏûàÏñ¥ÏÑú Ìï¥Îãπ ÌñâÏùÄ ÏÇ≠Ï†ú(24rows)\n",
    "cleaned_data = data.dropna(subset=['Target_DM']).copy()\n",
    "target_val =cleaned_data['Target_DM']                                   ### yÏóê Ìï¥ÎãπÌï®\n",
    "\n",
    "drop_cols = ['HE_Ucot', 'HE_FVC', 'HE_Frtn','Target_HT','Target_DM']                   \n",
    "df = cleaned_data.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8224a9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Í∞Å Î∞©ÏãùÏúºÎ°ú Í≤∞Ï∏°Ïπò ÎåÄÏ≤¥\n",
    "data_mice = impute_mice(df.copy())\n",
    "data_knn = impute_knn(df.copy())\n",
    "\n",
    "# autoencoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_e = StandardScaler()\n",
    "df_scaled = scaler_e.fit_transform(df)\n",
    "df_tensor = torch.tensor(df_scaled, dtype=torch.float32)\n",
    "data_autoencoder = predictMyModel(model,df_tensor)\n",
    "\n",
    "# 2-2. Ïä§ÏºÄÏùºÎßÅ Î≥µÏõê\n",
    "data_mymodel = scaler_e.inverse_transform(data_autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cd3172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_show import *\n",
    "# 3. Í∞Å Îç∞Ïù¥ÌÑ∞ÏÖãÏúºÎ°ú Î∂ÑÎ•ò Î™®Îç∏ (Í≤∞Ï†ïÌä∏Î¶¨)Î°ú ÏÑ±Îä• ÎπÑÍµê\n",
    "def evaluate_classifier(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Î™®Îç∏ Ï†ïÏùò\n",
    "    models = {\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),     #scale_pos_weight=scale_pos_weight\n",
    "        \"LightGBM\": LGBMClassifier(random_state=42,is_unbalance=True)\n",
    "    }\n",
    "    \n",
    "    result(models,X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de381852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dibaeck/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [15:47:24] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 698, number of negative: 15282\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6630\n",
      "[LightGBM] [Info] Number of data points in the train set: 15980, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.043680 -> initscore=-3.086212\n",
      "[LightGBM] [Info] Start training from score -3.086212\n",
      "################## ÏÑ±Îä• ÎπÑÍµê : {name} #####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dibaeck/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/dibaeck/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.0948</td>\n",
       "      <td>0.5680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.9559</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.6657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.9557</td>\n",
       "      <td>0.1449</td>\n",
       "      <td>0.6507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.3657</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>0.6422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Accuracy  F1 Score  ROC AUC\n",
       "Decision Tree    0.9474    0.0948   0.5680\n",
       "Random Forest    0.9559    0.1200   0.6657\n",
       "XGBoost          0.9557    0.1449   0.6507\n",
       "LightGBM         0.3657    0.1071   0.6422"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_classifier(data_mymodel,target_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0cf8fc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dibaeck/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [15:48:13] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 698, number of negative: 15282\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3683\n",
      "[LightGBM] [Info] Number of data points in the train set: 15980, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.043680 -> initscore=-3.086212\n",
      "[LightGBM] [Info] Start training from score -3.086212\n",
      "################## ÏÑ±Îä• ÎπÑÍµê : {name} #####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dibaeck/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/dibaeck/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.3877</td>\n",
       "      <td>0.7033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.9605</td>\n",
       "      <td>0.3730</td>\n",
       "      <td>0.9293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.9599</td>\n",
       "      <td>0.4771</td>\n",
       "      <td>0.9225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.9467</td>\n",
       "      <td>0.5319</td>\n",
       "      <td>0.9242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Accuracy  F1 Score  ROC AUC\n",
       "Decision Tree    0.9352    0.3877   0.7033\n",
       "Random Forest    0.9605    0.3730   0.9293\n",
       "XGBoost          0.9599    0.4771   0.9225\n",
       "LightGBM         0.9467    0.5319   0.9242"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_classifier(data_mice,target_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b39b22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dibaeck/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [15:48:53] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 698, number of negative: 15282\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046341 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3628\n",
      "[LightGBM] [Info] Number of data points in the train set: 15980, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.043680 -> initscore=-3.086212\n",
      "[LightGBM] [Info] Start training from score -3.086212\n",
      "################## ÏÑ±Îä• ÎπÑÍµê : {name} #####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dibaeck/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/dibaeck/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.3669</td>\n",
       "      <td>0.6765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.9612</td>\n",
       "      <td>0.4444</td>\n",
       "      <td>0.9161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.9615</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>0.9159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.5161</td>\n",
       "      <td>0.9112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Accuracy  F1 Score  ROC AUC\n",
       "Decision Tree    0.9387    0.3669   0.6765\n",
       "Random Forest    0.9612    0.4444   0.9161\n",
       "XGBoost          0.9615    0.4690   0.9159\n",
       "LightGBM         0.9474    0.5161   0.9112"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_classifier(data_knn,target_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39890e19",
   "metadata": {},
   "source": [
    "# Ï†ïÎ¶¨\n",
    "## üîç Í≤∞Ï∏°Ïπò ÎåÄÏ≤¥ Î∞©ÏãùÏóê Îî∞Î•∏ Î∂ÑÎ•ò ÏÑ±Îä• ÎπÑÍµê\n",
    "\n",
    "| Í≤∞Ï∏°Ïπò ÎåÄÏ≤¥ Î∞©Î≤ï | Accuracy ÌèâÍ∑† | F1 Score ÌèâÍ∑† | ROC AUC ÌèâÍ∑† |\n",
    "|------------------|---------------|----------------|----------------|\n",
    "| **Autoencoder** | 0.8061        | **0.1136**     | 0.6290         |\n",
    "| **MICE**         | 0.9506        | **0.4424**     | **0.8698**     |\n",
    "| **KNN**          | 0.9522        | **0.4491**     | 0.8549         |\n",
    "\n",
    "   #\n",
    "\n",
    "### üî∏ Autoencoder\n",
    "- **AccuracyÎäî ÎÜíÏùÄ Ìé∏**Ïù¥ÎÇò, **F1 ScoreÍ∞Ä Îß§Ïö∞ ÎÇÆÏùå (0.11)** ‚Üí **Î∂àÍ∑†Ìòï ÌÅ¥ÎûòÏä§ Î¨∏Ï†úÏóêÏÑú Î∂ÄÏ†ÅÌï©**ÌñàÏùÑ Í∞ÄÎä•ÏÑ± ÌÅº.\n",
    "- ROC AUCÎèÑ **0.63** ÏàòÏ§ÄÏúºÎ°ú, ÏòàÏ∏°Î†•Ïù¥ ÎÇÆÏùå.\n",
    "- ÌäπÌûà LightGBM Î™®Îç∏ÏóêÏÑú AccuracyÍ∞Ä **36%**Î°ú Í∏âÎùΩ ‚Üí AutoencoderÍ∞Ä ÌäπÏ†ï Íµ¨Ï°∞Î•º Ïûò Î≥µÏõê Î™ªÌñàÏùÑ ÏàòÎèÑ ÏûàÏùå.\n",
    "\n",
    "> ‚úÖ **Ï†ïÎ¶¨**: Ï†ïÌôïÎèÑÎäî ÎÜíÏïÑ Î≥¥Ïù¥ÏßÄÎßå, Ïã§Ï†úÎ°úÎäî **ÏÜåÏàò ÌÅ¥ÎûòÏä§ Î∂ÑÎ•òÎ•º Í±∞Ïùò Î™ªÌïòÎäî ÏÉÅÌÉú**.  \n",
    "> F1Ïù¥ 0.1ÎåÄÎ©¥ Í±∞Ïùò ÏòàÏ∏°ÏùÑ Ïïà Ìïú ÏàòÏ§Ä.\n",
    "\n",
    "   #\n",
    "\n",
    "### üî∏ MICE\n",
    "- **F1 Score, ROC AUC Î™®Îëê Í∞ÄÏû• Ïö∞ÏàòÌï®** ‚Üí **Î∂àÍ∑†Ìòï Îç∞Ïù¥ÌÑ∞ÏóêÏÑúÎèÑ ÏïàÏ†ïÏ†ÅÏúºÎ°ú ÌïôÏäµ**Îê®.\n",
    "- ÌäπÌûà **LightGBMÏùò F1Ïù¥ 0.53, ROC AUCÏù¥ 0.92**Î°ú Îõ∞Ïñ¥ÎÇ®.\n",
    "\n",
    "> ‚úÖ **Ï†ïÎ¶¨**: Ï†ÑÏ≤¥Ï†ÅÏúºÎ°ú Í∞ÄÏû• Í∑†Ìòï Ïû°Ìûå ÏÑ±Îä•.  \n",
    "> ÏÜåÏàò ÌÅ¥ÎûòÏä§ÎèÑ ÎπÑÍµêÏ†Å Ïûò Ïû°Í≥†, Ï†ÑÎ∞òÏ†ÅÏù∏ Î™®Îç∏Îì§Ïù¥ MICEÎ•º Í∏∞Î∞òÏúºÎ°ú Í∞ÄÏû• Ï¢ãÏùÄ ÏÑ±Îä•ÏùÑ ÎÉÑ.\n",
    "\n",
    "   #\n",
    "\n",
    "### üî∏ KNN\n",
    "- MICEÎ≥¥Îã§Îäî ÏïΩÍ∞Ñ ÎÇÆÏßÄÎßå Ïó¨Ï†ÑÌûà **F1 ScoreÏôÄ ROC AUC**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f84a74",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fa0940",
   "metadata": {},
   "source": [
    "## **üìä Flow2**\n",
    "> step01 : ÌÅ¥ÎûòÏä§ Î∂ÑÌè¨ ÌôïÏù∏  \n",
    "> - `Target_DM`, `Target_HT`Ïùò ÌÅ¥ÎûòÏä§ ÎπÑÏú® ÏãúÍ∞ÅÌôî Î∞è Î∂àÍ∑†Ìòï Ïó¨Î∂Ä ÌååÏïÖ  \n",
    "> - ÏÜåÏàò ÌÅ¥ÎûòÏä§Ïùò ÎπÑÏú®Ïù¥ ÌòÑÏ†ÄÌûà ÎÇÆÏùÄ Í≤ΩÏö∞ ‚Üí Î∂àÍ∑†Ìòï Î¨∏Ï†ú Ï°¥Ïû¨ ÌåêÎã®  \n",
    "\n",
    "#\n",
    "\n",
    "> step02 : Î∂àÍ∑†Ìòï Î¨∏Ï†ú Ìï¥Í≤∞ Ï†ÑÎûµ Ï†ÅÏö©  \n",
    "> - ÌïôÏäµ Îç∞Ïù¥ÌÑ∞Ïóê ÎåÄÌï¥ Îã§ÏñëÌïú Í∏∞Î≤ï Ï†ÅÏö©  \n",
    ">     - **SMOTE** : ÏÜåÏàò ÌÅ¥ÎûòÏä§ ÏÉòÌîåÏùÑ Ìï©ÏÑ±ÌïòÏó¨ Îç∞Ïù¥ÌÑ∞ Ï¶ùÍ∞ï  \n",
    ">     - **Ïñ∏ÎçîÏÉòÌîåÎßÅ** : Îã§Ïàò ÌÅ¥ÎûòÏä§ ÏÉòÌîå ÏàòÎ•º Ï§ÑÏó¨ Í∑†Ìòï ÎßûÏ∂§  \n",
    ">     - **Class Weight** : Î™®Îç∏ ÌïôÏäµ Ïãú ÏÜêÏã§ Ìï®ÏàòÏóê Í∞ÄÏ§ëÏπò Î∂ÄÏó¨ (`class_weight='balanced'`)  \n",
    ">     - **ÏïôÏÉÅÎ∏î Í∏∞Î≤ï** : Î™®Îç∏ ÏÑ±Îä• Ìñ•ÏÉÅÏùÑ ÏúÑÌïú Îã§Ïàò Î™®Îç∏ Ï°∞Ìï©  \n",
    "\n",
    "#\n",
    "\n",
    "> step03 : Ï†ÑÎûµ Ï†ÅÏö©Ìïú ÏÉÅÌÉúÎ°ú Î™®Îç∏ ÎπÑÍµê\n",
    "> - Í∏∞Î≥∏ Î™®Îç∏: RandomForest, XGBoost, ÌòπÏùÄ Îî•Îü¨Îãù Í∏∞Î∞ò Î™®Îç∏  \n",
    "> - ÏÑ±Îä• ÌèâÍ∞Ä ÏßÄÌëú:  \n",
    ">     - Accuracy  \n",
    ">     - Precision, Recall, F1-score (ÌäπÌûà ÏÜåÏàò ÌÅ¥ÎûòÏä§ Ï§ëÏã¨ ÌèâÍ∞Ä)  \n",
    ">     - AUC-ROC  \n",
    "\n",
    "#\n",
    "\n",
    "> step04 : Î∂ÑÎ•ò Î™®Îç∏ Í∞úÎ∞ú  ÏÑ±Îä• ÌèâÍ∞Ä  \n",
    "> - Í∏∞Î≥∏ Î™®Îç∏: RandomForest, XGBoost, ÌòπÏùÄ Îî•Îü¨Îãù Í∏∞Î∞ò Î™®Îç∏  \n",
    "> - ÏÑ±Îä• ÌèâÍ∞Ä ÏßÄÌëú:  \n",
    ">     - Accuracy  \n",
    ">     - Precision, Recall, F1-score (ÌäπÌûà ÏÜåÏàò ÌÅ¥ÎûòÏä§ Ï§ëÏã¨ ÌèâÍ∞Ä)  \n",
    ">     - AUC-ROC  \n",
    "\n",
    "#\n",
    "\n",
    "> step05 : Îã§ÏñëÌïú Î∂àÍ∑†Ìòï Ìï¥Í≤∞ Í∏∞Î≤ï Í∞Ñ ÏÑ±Îä• ÎπÑÍµê  \n",
    "> - ÏúÑ ÏßÄÌëúÎì§ÏùÑ Î∞îÌÉïÏúºÎ°ú Ï†ÅÏö©Îêú Î∂àÍ∑†Ìòï Ï≤òÎ¶¨ Ï†ÑÎûµÎì§Ïùò Ìö®Í≥º ÎπÑÍµê  \n",
    "> - ÏµúÏ†ÅÏùò Ï†ÑÎûµ ÏÑ†ÌÉù Î∞è Î™®Îç∏ ÏµúÏ¢Ö ÏÑ†Ï†ï\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e08dea",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 01   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2620d535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_result = pd.read_csv(\"Data_01_imputed_result.csv\")\n",
    "\n",
    "# ÌÅ¥ÎûòÏä§ Î∂àÍ∑†Ìòï ÌôïÏù∏\n",
    "print(df_result['Target_DM'].value_counts())\n",
    "print(df_result['Target_HT'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de85b97a",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 02   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f926e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE  # SMOTEÎ•º ÏúÑÌïú Ìå®ÌÇ§ÏßÄ\n",
    "from imblearn.under_sampling import RandomUnderSampler  # Ïñ∏ÎçîÏÉòÌîåÎßÅ ÏòµÏÖò\n",
    "from imblearn.pipeline import Pipeline  # Ïó¨Îü¨ Ïä§ÌÖùÏùÑ Ïó∞Í≤∞\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def data_processing_ver2(df_result,columns_name):\n",
    "    \"\"\"\n",
    "    Î∂àÍ∑†Ìòï Í≥†Î†§ÌïòÏßÄ ÏïäÏùÄ Îç∞Ïù¥ÌÑ∞\n",
    "    \"\"\"\n",
    "    # 1. Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ\n",
    "    x = df_result.drop(columns=[columns_name])  \n",
    "    y = df_result[columns_name].astype(int)  # ÌÉÄÍ≤ü\n",
    "\n",
    "    # 2. ÌïôÏäµ/ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ Î∂ÑÎ¶¨\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 3. Ïä§ÏºÄÏùºÎßÅ\n",
    "    scaler = StandardScaler()\n",
    "    x_train_scaled = scaler.fit_transform(x_train)\n",
    "    x_test_scaled = scaler.transform(x_test)\n",
    "    \n",
    "    return x_train_scaled,x_test_scaled, y_train, y_test, scaler\n",
    "\n",
    "\n",
    "def resample_data(X, y, method='both', random_state=42):\n",
    "    \"\"\"\n",
    "    Î∂àÍ∑†Ìòï Í≥†Î†§\n",
    "    SMOTE, Ïñ∏ÎçîÏÉòÌîåÎßÅ, ÎòêÎäî ÌòºÌï© Î∞©ÏãùÏúºÎ°ú Îç∞Ïù¥ÌÑ∞ Î¶¨ÏÉòÌîåÎßÅÏùÑ ÏàòÌñâÌïòÎäî Ìï®Ïàò.\n",
    "    \n",
    "    \"\"\"\n",
    "    if method == 'smote':\n",
    "        sampler = SMOTE(random_state=random_state)\n",
    "    elif method == 'under':\n",
    "        sampler = RandomUnderSampler(random_state=random_state)\n",
    "    elif method == 'both':\n",
    "        sampler = Pipeline([\n",
    "            ('over', SMOTE(random_state=random_state)),\n",
    "            ('under', RandomUnderSampler(random_state=random_state))\n",
    "        ])\n",
    "\n",
    "    X_resampled, y_resampled = sampler.fit_resample(X, y)\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "X = df_result\n",
    "x_train_scaled, x_test_scaled, y_train,y_test, ss = data_processing_ver2(X,'Target_DM')         # 'Target_HT'\n",
    "X_resampled, y_resampled = resample_data(x_train_scaled, y_train, method='smote')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343d2259",
   "metadata": {},
   "source": [
    "## step04 : Î∂àÍ∑†Ìòï Í≥†Î†§Ìïú ÏÉÅÌÉúÎ°ú Î™®Îç∏ ÎπÑÍµê\n",
    "> - Í∏∞Î≥∏ Î™®Îç∏: RandomForest, XGBoost, ÌòπÏùÄ Îî•Îü¨Îãù Í∏∞Î∞ò Î™®Îç∏  \n",
    "> - ÏÑ±Îä• ÌèâÍ∞Ä ÏßÄÌëú:  \n",
    ">     - Accuracy  \n",
    ">     - Precision, Recall, F1-score (ÌäπÌûà ÏÜåÏàò ÌÅ¥ÎûòÏä§ Ï§ëÏã¨ ÌèâÍ∞Ä)  \n",
    ">     - AUC-ROC  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f785506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_show import *\n",
    "\n",
    "# neg, pos = y_DM_train.value_counts()\n",
    "# scale_pos_weight = neg / pos\n",
    "\n",
    "# Î™®Îç∏ Ï†ïÏùò\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),     #scale_pos_weight=scale_pos_weight\n",
    "    \"LightGBM\": LGBMClassifier(random_state=42,is_unbalance=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03293358",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dm_both = result(models, X_resampled, x_test_scaled, y_resampled,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fcca27",
   "metadata": {},
   "source": [
    "## ‚úÖ Îç∞Ïù¥ÌÑ∞ Î∂àÍ∑†Ìòï Í≥†Î†§ ÌõÑ Î™®Îç∏ ÏÑ±Îä• (Autoencoder Í≤∞Ï∏°Ïπò ÎåÄÏ≤¥ Í∏∞Î∞ò)\n",
    "\n",
    "| Î™®Îç∏            | Accuracy | F1 Score | ROC AUC |\n",
    "|-----------------|----------|----------|----------|\n",
    "| Decision Tree   | 0.9119   | 0.3308   | 0.7041   |\n",
    "| Random Forest   | 0.9534   | 0.5079   | 0.9307   |\n",
    "| XGBoost         | 0.9552   | 0.4559   | 0.9195   |\n",
    "| LightGBM        | 0.9562   | 0.5098   | 0.9307   |\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Ìï¥ÏÑù\n",
    "\n",
    "- **Îç∞Ïù¥ÌÑ∞ Î∂àÍ∑†ÌòïÏùÑ Í≥†Î†§Ìïú ÌõÑ**, Ï†ÑÎ∞òÏ†ÅÏúºÎ°ú Î™®Îì† Î™®Îç∏Ïùò **F1 ScoreÏôÄ ROC AUCÍ∞Ä ÌÅ¨Í≤å Ìñ•ÏÉÅÎê®**.\n",
    "- ÌäπÌûà `Random Forest`, `LightGBM` Î™®Îç∏ÏùÄ **0.5 Ïù¥ÏÉÅÏùò F1 Score**, **0.93Ïùò AUC**Î•º Î≥¥Ïó¨ Îß§Ïö∞ Ïö∞ÏàòÌïú ÏÑ±Îä•ÏùÑ Î≥¥ÏûÑ.\n",
    "- `Decision Tree`Îäî Í∞ÄÏû• ÎÇÆÏùÄ F1 ScoreÎ•º Î≥¥ÏòÄÏßÄÎßå, Ïù¥Ï†ÑÎ≥¥Îã§ Í∞úÏÑ†Îêú ÏÑ±Îä•.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ ÏöîÏïΩ\n",
    "\n",
    "> Îç∞Ïù¥ÌÑ∞ Î∂àÍ∑†Ìòï Î¨∏Ï†úÎ•º Ï≤òÎ¶¨Ìïú Ïù¥ÌõÑ, AutoencoderÎ°ú Í≤∞Ï∏°ÏπòÎ•º ÎåÄÏ≤¥Ìïú Îç∞Ïù¥ÌÑ∞ÎèÑ **Ï∂©Î∂ÑÌûà Ï¢ãÏùÄ Î∂ÑÎ•ò ÏÑ±Îä•**ÏùÑ ÎÇº Ïàò ÏûàÏùå.  \n",
    "> ÌäπÌûà **LightGBM, Random Forest** Î™®Îç∏ÏùÄ **Ï†ïÌôïÎèÑ, Ï†ïÎ∞ÄÎèÑ, ÏòàÏ∏°Î†• Î™®Îëê Ïö∞Ïàò**Ìïú Í≤∞Í≥ºÎ•º Î≥¥ÏûÑ.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc651552",
   "metadata": {},
   "source": [
    "## step04 : Î∂ÑÎ•ò Î™®Îç∏ Í∞úÎ∞ú  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728ba5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "################ ÏûÖÎ†• Îç∞Ïù¥ÌÑ∞ Ï°∞Ï†ï\n",
    "x_DM_train = x_train_scaled\n",
    "\n",
    "# ÏùòÏÇ¨Í≤∞Ï†ïÎÇòÎ¨¥ Î™®Îç∏ ÌïôÏäµ : ÌÅ¥ÎûòÏä§ Î∂àÍ∑†Ìòï\n",
    "dt_model = DecisionTreeClassifier(random_state=42)                          # option : class_weight='balanced'\n",
    "dt_model.fit(x_DM_train, y_train)\n",
    "\n",
    "# ÏòàÏ∏° Î∞è ÌèâÍ∞Ä\n",
    "y_pred = dt_model.predict(x_test_scaled)\n",
    "y_proba = dt_model.predict(x_test_scaled)\n",
    "\n",
    "# ÏÑ±Îä• ÏßÄÌëú Í≥ÑÏÇ∞\n",
    "metrics = calculate_metrics(y_test,y_pred,y_proba)\n",
    "\n",
    "# Î≥¥Í∏∞ Ï¢ãÍ≤å Ï†ïÎ¶¨\n",
    "metrics_df = pd.DataFrame.from_dict(metrics, orient='index', columns=['Score'])\n",
    "print(\"‚ñ∂Ô∏è Îã§ÏñëÌïú Î∂ÑÎ•ò ÏÑ±Îä• ÏßÄÌëú\")\n",
    "display(metrics_df.round(4))\n",
    "\n",
    "# Ï∂îÍ∞ÄÎ°ú Classification Report Ï†ÑÏ≤¥ Ï∂úÎ†•\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9376ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ÌïòÏù¥Ìçº ÌååÎùºÎØ∏ÌÑ∞ ÌäúÎãù\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# ÏùòÏÇ¨Í≤∞Ï†ïÎÇòÎ¨¥ Î™®Îç∏\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ Í∑∏Î¶¨Îìú ÏÑ§Ï†ï\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# GridSearchCV ÏÑ§Ï†ï\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=dt,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',  # Îã§Î•∏ Ï†êÏàòÎèÑ Í∞ÄÎä•: accuracy, roc_auc Îì±\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ÌïôÏäµ\n",
    "grid_search.fit(x_DM_train, y_train)\n",
    "\n",
    "# Í≤∞Í≥º Ï∂úÎ†•\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best F1 Score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f697b485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÏµúÏ†Å Î™®Îç∏Î°ú Ïû¨ÌèâÍ∞Ä : \n",
    "best_dt = grid_search.best_estimator_\n",
    "y_pred_best = best_dt.predict(x_test_scaled)\n",
    "y_proba_best = best_dt.predict_proba(x_test_scaled)[:, 1]\n",
    "\n",
    "best_metrics = calculate_metrics(y_test,y_pred,y_proba)\n",
    "\n",
    "print(\"\\n‚ñ∂Ô∏è ÏµúÏ†Å Î™®Îç∏ ÏÑ±Îä•\")\n",
    "display(pd.DataFrame.from_dict(best_metrics, orient='index', columns=['Score']).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0388a602",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc(best_dt,x_test_scaled,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e13c523",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_result.drop(['Target_HT'], axis=1)  # ÏûÖÎ†• Î≥ÄÏàò\n",
    "show_feature_importance(best_dt,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a844cc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_decision_tree(best_dt,X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086bb12a",
   "metadata": {},
   "source": [
    "---\n",
    "## Step05 : ÏïôÏÉÅÎ∏î Î™®Îç∏ Ïù¥Ïö©ÌïòÏó¨ Î∂ÑÎ•ò Î™®Îç∏ ÏÑ±Îä• ÎπÑÍµê   \n",
    "\n",
    "> - Í∏∞Î≥∏ Î™®Îç∏: RandomForest, XGBoost, ÌòπÏùÄ Îî•Îü¨Îãù Í∏∞Î∞ò Î™®Îç∏  \n",
    "> - ÏÑ±Îä• ÌèâÍ∞Ä ÏßÄÌëú:  \n",
    ">     - Accuracy  \n",
    ">     - Precision, Recall, F1-score (ÌäπÌûà ÏÜåÏàò ÌÅ¥ÎûòÏä§ Ï§ëÏã¨ ÌèâÍ∞Ä)  \n",
    ">     - AUC-ROC  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7e6979",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "# neg, pos = y_DM_train.value_counts()\n",
    "# scale_pos_weight = neg / pos\n",
    "\n",
    "# Î™®Îç∏ Ï†ïÏùò\n",
    "models = {\n",
    "    \"tuning_Decision Tree\": best_dt,\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),     #scale_pos_weight=scale_pos_weight\n",
    "    \"LightGBM\": LGBMClassifier(random_state=42,is_unbalance=True)\n",
    "}\n",
    "\n",
    "result(models, X_resampled, x_test_scaled, y_resampled,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b7b6f9",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dibk311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
