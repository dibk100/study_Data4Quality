{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d09a5f0",
   "metadata": {},
   "source": [
    "---\n",
    "## **📊 Flow**   \n",
    "> step01 : Data   \n",
    "> - 데이터 준비 및 분석   \n",
    "> - 데이터 전처리\n",
    "   #   \n",
    "> setp02 : 비교 모델    \n",
    "> - ResNet50, EfficientNet,VGG16\n",
    "> - 모델 학습\n",
    "> - 성능평가 : 정확도 재현율 f1\n",
    "   #\n",
    "> setp03 : 성능 개선   \n",
    "> ResNet50, EfficientNet,VGG16 모델들 **앙상블**   \n",
    "> 성능평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bdfc80",
   "metadata": {},
   "source": [
    "---\n",
    "> ### step01 : Data   \n",
    "> - 데이터 준비 및 분석   \n",
    "> - 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed597957",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataprocessing import *\n",
    "\n",
    "# 데이터 경로\n",
    "data_path = '/home/dibaeck/sketch/study_Data4Quality/task02_CovidClassifier/COVID19_1K'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd80077",
   "metadata": {},
   "source": [
    "---\n",
    ">> 데이터 사이즈 다름 --> TASK : 데이터 리사이즈  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84997161",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_image_sizes(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f345db94",
   "metadata": {},
   "source": [
    "---\n",
    ">> 클래스 불균형 : COVID19 데이터가 적음.  --> TASK : Data Augmentation   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb00a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_and_visualize_images(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9793bbb",
   "metadata": {},
   "source": [
    "클래스 불균형 해결 전략 : WeightedRandomSampler + FocalLoss\n",
    "\n",
    "| 전략               | 설명                                                                 |\n",
    "|--------------------|----------------------------------------------------------------------|\n",
    "| **WeightedRandomSampler**          | 수 클래스를 더 자주 뽑히게 하는 샘플링 방식                |\n",
    "| **Focal Loss**     | 소수 클래스의 어려운 샘플에 더 집중하는 loss function(의료 이미지에서 성능 개선에 효과적)                               |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503ffc26",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abac0d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## setting \n",
    "from dataprocessing import *\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "# 데이터 경로\n",
    "data_path = '/home/dibaeck/sketch/study_Data4Quality/task02_CovidClassifier/COVID19_1K'\n",
    "\n",
    "# 데이터 정규화 및 리사이즈, 텐서화\n",
    "transform = get_transform()\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = get_datasets(data_path, transform)\n",
    "\n",
    "# 데이터 로더 batch size 32\n",
    "train_loader = DataLoader(train_dataset, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e779971a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "# 모델 훈련 및 평가 함수\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='binary' if len(set(y_test)) == 2 else 'micro')\n",
    "    recall = recall_score(y_test, y_pred, average='binary' if len(set(y_test)) == 2 else 'micro')\n",
    "    f1 = f1_score(y_test, y_pred, average='binary' if len(set(y_test)) == 2 else 'micro')\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{confusion}\")\n",
    "\n",
    "# 이진 분류를 위한 데이터 준비 (PNEUMONIA vs NORMAL 등)\n",
    "def prepare_data_for_binary_classification(loader, class_1_idx, class_2_idx):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for inputs, targets in loader:\n",
    "        # 특정 클래스에 해당하는 것만 필터링\n",
    "        binary_labels = torch.where(targets == class_1_idx, 1, 0)  # class_1_idx를 1로, 나머지는 0으로\n",
    "        data.append(inputs.view(inputs.size(0), -1).numpy())  # 이미지를 1D 벡터로 변환\n",
    "        labels.append(binary_labels.numpy())\n",
    "    return np.concatenate(data), np.concatenate(labels)\n",
    "\n",
    "# 다중 클래스 분류를 위한 데이터 준비\n",
    "def prepare_data_for_multi_classification(loader):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for inputs, targets in loader:\n",
    "        data.append(inputs.view(inputs.size(0), -1).numpy())  # 이미지를 1D 벡터로 변환\n",
    "        labels.append(targets.numpy())\n",
    "    return np.concatenate(data), np.concatenate(labels)\n",
    "\n",
    "# 모델 훈련 및 성능 비교 함수\n",
    "def train_and_evaluate_models(train_loader, test_loader):\n",
    "    # 1) PNEUMONIA vs NORMAL (이진 분류)\n",
    "    X_train_pneumonia, y_train_pneumonia = prepare_data_for_binary_classification(train_loader, class_1_idx=0, class_2_idx=1)\n",
    "    X_test_pneumonia, y_test_pneumonia = prepare_data_for_binary_classification(test_loader, class_1_idx=0, class_2_idx=1)\n",
    "    \n",
    "    # 모델: 로지스틱 회귀\n",
    "    model_pneumonia = RandomForestClassifier(n_estimators=100)\n",
    "    model_pneumonia.fit(X_train_pneumonia, y_train_pneumonia)\n",
    "    \n",
    "    print(\"PNEUMONIA vs NORMAL Model Performance:\")\n",
    "    evaluate_model(model_pneumonia, X_test_pneumonia, y_test_pneumonia)\n",
    "\n",
    "    # 2) COVID19 vs NORMAL (이진 분류)\n",
    "    X_train_covid, y_train_covid = prepare_data_for_binary_classification(train_loader, class_1_idx=1, class_2_idx=2)\n",
    "    X_test_covid, y_test_covid = prepare_data_for_binary_classification(test_loader, class_1_idx=1, class_2_idx=2)\n",
    "    \n",
    "    model_covid = RandomForestClassifier(n_estimators=100)\n",
    "    model_covid.fit(X_train_covid, y_train_covid)\n",
    "    \n",
    "    print(\"\\nCOVID19 vs NORMAL Model Performance:\")\n",
    "    evaluate_model(model_covid, X_test_covid, y_test_covid)\n",
    "\n",
    "    # 3) Multi-class: COVID19 vs PNEUMONIA vs NORMAL (다중 클래스 분류)\n",
    "    X_train_multi, y_train_multi = prepare_data_for_multi_classification(train_loader)\n",
    "    X_test_multi, y_test_multi = prepare_data_for_multi_classification(test_loader)\n",
    "    \n",
    "    model_multi = RandomForestClassifier(n_estimators=100)\n",
    "    model_multi.fit(X_train_multi, y_train_multi)\n",
    "    \n",
    "    print(\"\\nMulti-class Model Performance (COVID19 vs PNEUMONIA vs NORMAL):\")\n",
    "    evaluate_model(model_multi, X_test_multi, y_test_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ed3ca83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNEUMONIA vs NORMAL Model Performance:\n",
      "Accuracy: 0.9655\n",
      "Precision: 0.9286\n",
      "Recall: 0.6842\n",
      "F1-Score: 0.7879\n",
      "Confusion Matrix:\n",
      "[[183   1]\n",
      " [  6  13]]\n",
      "\n",
      "COVID19 vs NORMAL Model Performance:\n",
      "Accuracy: 0.9360\n",
      "Precision: 0.9744\n",
      "Recall: 0.7600\n",
      "F1-Score: 0.8539\n",
      "Confusion Matrix:\n",
      "[[152   1]\n",
      " [ 12  38]]\n",
      "\n",
      "Multi-class Model Performance (COVID19 vs PNEUMONIA vs NORMAL):\n",
      "Accuracy: 0.9064\n",
      "Precision: 0.9064\n",
      "Recall: 0.9064\n",
      "F1-Score: 0.9064\n",
      "Confusion Matrix:\n",
      "[[ 12   1   6]\n",
      " [  1  39  10]\n",
      " [  1   0 133]]\n"
     ]
    }
   ],
   "source": [
    "# 모델 훈련 및 평가 실행\n",
    "train_and_evaluate_models(train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a879e7a3",
   "metadata": {},
   "source": [
    "### 모델 성능 비교\n",
    "\n",
    "| **모델**                          | **정확도 (Accuracy)** | **정밀도 (Precision)** | **재현율 (Recall)** | **F1-Score** | **Confusion Matrix**                                |\n",
    "|-----------------------------------|----------------------|------------------------|---------------------|--------------|-----------------------------------------------------|\n",
    "| **PNEUMONIA vs NORMAL**           | 0.9655               | 0.9286                 | 0.6842              | 0.7879       | [[183   1] <br> [  6  13]]                         |\n",
    "| **COVID19 vs NORMAL**             | 0.9360               | 0.9744                 | 0.7600              | 0.8539       | [[152   1] <br> [ 12  38]]                         |\n",
    "| **Multi-class (COVID19 vs PNEUMONIA vs NORMAL)** | 0.9064 | 0.9064 | 0.9064 | 0.9064 | [[ 12   1   6] <br> [  1  39  10] <br> [  1   0 133]] |\n",
    "\n",
    "---\n",
    "\n",
    "### 결론\n",
    "\n",
    "- **PNEUMONIA vs NORMAL 모델**: 높은 정확도와 정밀도, 하지만 재현율이 상대적으로 낮습니다.\n",
    "- **COVID19 vs NORMAL 모델**: 높은 정확도, 정밀도, 재현율을 보이며, 비교적 균형 잡힌 성능을 보여줍니다.\n",
    "- **Multi-class 모델**: 세 가지 클래스에 대해 고른 성능을 보여주며, F1-Score와 정확도가 90% 이상으로 우수합니다.\n",
    "\n",
    "**최종 평가**:\n",
    "- **COVID19 vs NORMAL 모델**은 정밀도와 재현율이 균형을 이루어 가장 우수한 성능을 보입니다.\n",
    "- **Multi-class 모델**은 세 가지 클래스를 잘 분리하며 좋은 성능을 보였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1567860a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bee5d4c",
   "metadata": {},
   "source": [
    "1]Multi-class분류에서 사용된 loss 가 모든 클래스에 적절했는지 분석하고,Focal loss,class-balancedloss등을 적용한 실험을 수행해보세요.\n",
    "\n",
    "1) Loss 함수 분석 및 Focal Loss, Class-Balanced Loss 실험   \n",
    "Multi-class 분류에서 기본적으로 사용되는 loss 함수는 Cross-Entropy Loss입니다. 이를 Focal Loss나 Class-Balanced Loss로 변경하여 성능을 비교할 수 있습니다.\n",
    "   \n",
    "Focal Loss:   \n",
    "Focal Loss는 클래스 불균형 문제를 해결하기 위한 loss 함수입니다. Cross-Entropy Loss는 클래스 간 불균형이 심할 때 성능이 떨어질 수 있는데, Focal Loss는 어려운 샘플에 가중치를 주어 성능을 개선할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "002292aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dibaeck/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, alpha=0.25, num_classes=3):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.num_classes = num_classes\n",
    "        self.ce_loss = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = self.ce_loss(inputs, targets)\n",
    "        pt = torch.exp(-ce_loss)  # For each class\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "        return focal_loss.mean()\n",
    "    \n",
    "class ClassBalancedLoss(nn.Module):\n",
    "    def __init__(self, class_weights):\n",
    "        super(ClassBalancedLoss, self).__init__()\n",
    "        self.class_weights = class_weights\n",
    "        self.ce_loss = nn.CrossEntropyLoss(weight=self.class_weights)\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        return self.ce_loss(inputs, targets)\n",
    "    \n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "def adjust_threshold(predictions, targets, threshold=0.5):\n",
    "    pred_classes = (predictions[:, 1] > threshold).float()  # COVID-19 클래스의 확률을 기준으로 예측\n",
    "    precision = precision_score(targets, pred_classes, average='binary', pos_label=1)\n",
    "    recall = recall_score(targets, pred_classes, average='binary', pos_label=1)\n",
    "    return precision, recall\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import models\n",
    "\n",
    "class GradCAM:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "\n",
    "    def save_gradient(self, grad):\n",
    "        self.gradients = grad\n",
    "\n",
    "    def forward(self, x):\n",
    "        activations = self.model.features(x)\n",
    "        activations.register_hook(self.save_gradient)\n",
    "        return activations\n",
    "\n",
    "    def generate_gradcam(self, input_image, target_class):\n",
    "        activations = self.forward(input_image)\n",
    "        self.model.zero_grad()\n",
    "        activations[target_class].backward(retain_graph=True)\n",
    "        gradients = self.gradients\n",
    "        pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "        weighted_activations = activations * pooled_gradients.view(1, -1, 1, 1)\n",
    "        gradcam = torch.mean(weighted_activations, dim=1).squeeze()\n",
    "        gradcam = np.maximum(gradcam.cpu().detach().numpy(), 0)\n",
    "        gradcam = cv2.resize(gradcam, (input_image.size(2), input_image.size(3)))\n",
    "        return gradcam\n",
    "\n",
    "import shap\n",
    "import numpy as np\n",
    "\n",
    "# SHAP을 사용하여 모델 해석\n",
    "def explain_with_shap(model, dataloader):\n",
    "    explainer = shap.KernelExplainer(model.predict, data=dataloader)\n",
    "    shap_values = explainer.shap_values(dataloader)\n",
    "    shap.summary_plot(shap_values, dataloader)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def analyze_confusion_matrix(predictions, targets):\n",
    "    cm = confusion_matrix(targets, predictions)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# 예시: 오분류된 샘플에 대해 가중치를 더 주기\n",
    "def reweight_loss_function(model, predictions, targets):\n",
    "    # 잘못 분류된 샘플에 대해 가중치 증가\n",
    "    incorrect_samples = predictions != targets\n",
    "    weights = torch.where(incorrect_samples, 2.0, 1.0)\n",
    "    loss = F.cross_entropy(predictions, targets, weight=weights)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8222df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 시 사용될 loss 함수 설정\n",
    "criterion = FocalLoss(gamma=2, alpha=0.25, num_classes=3)  # 예시로 FocalLoss 사용\n",
    "\n",
    "# 학습 과정에서 해당 loss를 사용하여 모델 훈련\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73bbc3ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m thresholds = [\u001b[32m0.3\u001b[39m, \u001b[32m0.5\u001b[39m, \u001b[32m0.7\u001b[39m]  \u001b[38;5;66;03m# 여러 threshold 값 시도\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m threshold \u001b[38;5;129;01min\u001b[39;00m thresholds:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     precision, recall = adjust_threshold(\u001b[43mpredictions\u001b[49m, targets, threshold)\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThreshold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthreshold\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m -> Precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecision\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Recall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecall\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "thresholds = [0.3, 0.5, 0.7]  # 여러 threshold 값 시도\n",
    "for threshold in thresholds:\n",
    "    precision, recall = adjust_threshold(predictions, targets, threshold)\n",
    "    print(f\"Threshold: {threshold} -> Precision: {precision}, Recall: {recall}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8a18ad9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m gradcam = GradCAM(\u001b[43mmodel\u001b[49m)\n\u001b[32m      2\u001b[39m cam_output = gradcam.generate_gradcam(input_image, target_class)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# 결과를 시각화\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "gradcam = GradCAM(model)\n",
    "cam_output = gradcam.generate_gradcam(input_image, target_class)\n",
    "# 결과를 시각화\n",
    "plt.imshow(cam_output, cmap='jet')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68912131",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dibk311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
