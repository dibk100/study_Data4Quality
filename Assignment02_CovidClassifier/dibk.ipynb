{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d09a5f0",
   "metadata": {},
   "source": [
    "---\n",
    "## **ğŸ“Š Flow**   \n",
    "> step01 : Data   \n",
    "> - ë°ì´í„° ì¤€ë¹„ ë° ë¶„ì„   \n",
    "> - ë°ì´í„° ì „ì²˜ë¦¬\n",
    "   #   \n",
    "> setp02 : ë¹„êµ ëª¨ë¸    \n",
    "> - ResNet50, EfficientNet,VGG16\n",
    "> - ëª¨ë¸ í•™ìŠµ\n",
    "> - ì„±ëŠ¥í‰ê°€ : ì •í™•ë„ ì¬í˜„ìœ¨ f1\n",
    "   #\n",
    "> setp03 : ì„±ëŠ¥ ê°œì„    \n",
    "> ResNet50, EfficientNet,VGG16 ëª¨ë¸ë“¤ **ì•™ìƒë¸”**   \n",
    "> ì„±ëŠ¥í‰ê°€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bdfc80",
   "metadata": {},
   "source": [
    "---\n",
    "> ### step01 : Data   \n",
    "> - ë°ì´í„° ì¤€ë¹„ ë° ë¶„ì„   \n",
    "> - ë°ì´í„° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed597957",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataprocessing import *\n",
    "\n",
    "# ë°ì´í„° ê²½ë¡œ\n",
    "data_path = '/home/dibaeck/sketch/study_Data4Quality/task02_CovidClassifier/COVID19_1K'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd80077",
   "metadata": {},
   "source": [
    "---\n",
    ">> ë°ì´í„° ì‚¬ì´ì¦ˆ ë‹¤ë¦„ --> TASK : ë°ì´í„° ë¦¬ì‚¬ì´ì¦ˆ  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84997161",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_image_sizes(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f345db94",
   "metadata": {},
   "source": [
    "---\n",
    ">> í´ë˜ìŠ¤ ë¶ˆê· í˜• : COVID19 ë°ì´í„°ê°€ ì ìŒ.  --> TASK : Data Augmentation   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb00a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_and_visualize_images(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9793bbb",
   "metadata": {},
   "source": [
    "í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²° ì „ëµ : WeightedRandomSampler + FocalLoss\n",
    "\n",
    "| ì „ëµ               | ì„¤ëª…                                                                 |\n",
    "|--------------------|----------------------------------------------------------------------|\n",
    "| **WeightedRandomSampler**          | ìˆ˜ í´ë˜ìŠ¤ë¥¼ ë” ìì£¼ ë½‘íˆê²Œ í•˜ëŠ” ìƒ˜í”Œë§ ë°©ì‹                |\n",
    "| **Focal Loss**     | ì†Œìˆ˜ í´ë˜ìŠ¤ì˜ ì–´ë ¤ìš´ ìƒ˜í”Œì— ë” ì§‘ì¤‘í•˜ëŠ” loss function(ì˜ë£Œ ì´ë¯¸ì§€ì—ì„œ ì„±ëŠ¥ ê°œì„ ì— íš¨ê³¼ì )                               |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503ffc26",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abac0d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## setting \n",
    "from dataprocessing import *\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "# ë°ì´í„° ê²½ë¡œ\n",
    "data_path = '/home/dibaeck/sketch/study_Data4Quality/task02_CovidClassifier/COVID19_1K'\n",
    "\n",
    "# ë°ì´í„° ì •ê·œí™” ë° ë¦¬ì‚¬ì´ì¦ˆ, í…ì„œí™”\n",
    "transform = get_transform()\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = get_datasets(data_path, transform)\n",
    "\n",
    "# ë°ì´í„° ë¡œë” batch size 32\n",
    "train_loader = DataLoader(train_dataset, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e779971a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "# ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€ í•¨ìˆ˜\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='binary' if len(set(y_test)) == 2 else 'micro')\n",
    "    recall = recall_score(y_test, y_pred, average='binary' if len(set(y_test)) == 2 else 'micro')\n",
    "    f1 = f1_score(y_test, y_pred, average='binary' if len(set(y_test)) == 2 else 'micro')\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{confusion}\")\n",
    "\n",
    "# ì´ì§„ ë¶„ë¥˜ë¥¼ ìœ„í•œ ë°ì´í„° ì¤€ë¹„ (PNEUMONIA vs NORMAL ë“±)\n",
    "def prepare_data_for_binary_classification(loader, class_1_idx, class_2_idx):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for inputs, targets in loader:\n",
    "        # íŠ¹ì • í´ë˜ìŠ¤ì— í•´ë‹¹í•˜ëŠ” ê²ƒë§Œ í•„í„°ë§\n",
    "        binary_labels = torch.where(targets == class_1_idx, 1, 0)  # class_1_idxë¥¼ 1ë¡œ, ë‚˜ë¨¸ì§€ëŠ” 0ìœ¼ë¡œ\n",
    "        data.append(inputs.view(inputs.size(0), -1).numpy())  # ì´ë¯¸ì§€ë¥¼ 1D ë²¡í„°ë¡œ ë³€í™˜\n",
    "        labels.append(binary_labels.numpy())\n",
    "    return np.concatenate(data), np.concatenate(labels)\n",
    "\n",
    "# ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ë¥¼ ìœ„í•œ ë°ì´í„° ì¤€ë¹„\n",
    "def prepare_data_for_multi_classification(loader):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for inputs, targets in loader:\n",
    "        data.append(inputs.view(inputs.size(0), -1).numpy())  # ì´ë¯¸ì§€ë¥¼ 1D ë²¡í„°ë¡œ ë³€í™˜\n",
    "        labels.append(targets.numpy())\n",
    "    return np.concatenate(data), np.concatenate(labels)\n",
    "\n",
    "# ëª¨ë¸ í›ˆë ¨ ë° ì„±ëŠ¥ ë¹„êµ í•¨ìˆ˜\n",
    "def train_and_evaluate_models(train_loader, test_loader):\n",
    "    # 1) PNEUMONIA vs NORMAL (ì´ì§„ ë¶„ë¥˜)\n",
    "    X_train_pneumonia, y_train_pneumonia = prepare_data_for_binary_classification(train_loader, class_1_idx=0, class_2_idx=1)\n",
    "    X_test_pneumonia, y_test_pneumonia = prepare_data_for_binary_classification(test_loader, class_1_idx=0, class_2_idx=1)\n",
    "    \n",
    "    # ëª¨ë¸: ë¡œì§€ìŠ¤í‹± íšŒê·€\n",
    "    model_pneumonia = RandomForestClassifier(n_estimators=100)\n",
    "    model_pneumonia.fit(X_train_pneumonia, y_train_pneumonia)\n",
    "    \n",
    "    print(\"PNEUMONIA vs NORMAL Model Performance:\")\n",
    "    evaluate_model(model_pneumonia, X_test_pneumonia, y_test_pneumonia)\n",
    "\n",
    "    # 2) COVID19 vs NORMAL (ì´ì§„ ë¶„ë¥˜)\n",
    "    X_train_covid, y_train_covid = prepare_data_for_binary_classification(train_loader, class_1_idx=1, class_2_idx=2)\n",
    "    X_test_covid, y_test_covid = prepare_data_for_binary_classification(test_loader, class_1_idx=1, class_2_idx=2)\n",
    "    \n",
    "    model_covid = RandomForestClassifier(n_estimators=100)\n",
    "    model_covid.fit(X_train_covid, y_train_covid)\n",
    "    \n",
    "    print(\"\\nCOVID19 vs NORMAL Model Performance:\")\n",
    "    evaluate_model(model_covid, X_test_covid, y_test_covid)\n",
    "\n",
    "    # 3) Multi-class: COVID19 vs PNEUMONIA vs NORMAL (ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜)\n",
    "    X_train_multi, y_train_multi = prepare_data_for_multi_classification(train_loader)\n",
    "    X_test_multi, y_test_multi = prepare_data_for_multi_classification(test_loader)\n",
    "    \n",
    "    model_multi = RandomForestClassifier(n_estimators=100)\n",
    "    model_multi.fit(X_train_multi, y_train_multi)\n",
    "    \n",
    "    print(\"\\nMulti-class Model Performance (COVID19 vs PNEUMONIA vs NORMAL):\")\n",
    "    evaluate_model(model_multi, X_test_multi, y_test_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ed3ca83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNEUMONIA vs NORMAL Model Performance:\n",
      "Accuracy: 0.9655\n",
      "Precision: 0.9286\n",
      "Recall: 0.6842\n",
      "F1-Score: 0.7879\n",
      "Confusion Matrix:\n",
      "[[183   1]\n",
      " [  6  13]]\n",
      "\n",
      "COVID19 vs NORMAL Model Performance:\n",
      "Accuracy: 0.9360\n",
      "Precision: 0.9744\n",
      "Recall: 0.7600\n",
      "F1-Score: 0.8539\n",
      "Confusion Matrix:\n",
      "[[152   1]\n",
      " [ 12  38]]\n",
      "\n",
      "Multi-class Model Performance (COVID19 vs PNEUMONIA vs NORMAL):\n",
      "Accuracy: 0.9064\n",
      "Precision: 0.9064\n",
      "Recall: 0.9064\n",
      "F1-Score: 0.9064\n",
      "Confusion Matrix:\n",
      "[[ 12   1   6]\n",
      " [  1  39  10]\n",
      " [  1   0 133]]\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€ ì‹¤í–‰\n",
    "train_and_evaluate_models(train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a879e7a3",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ\n",
    "\n",
    "| **ëª¨ë¸**                          | **ì •í™•ë„ (Accuracy)** | **ì •ë°€ë„ (Precision)** | **ì¬í˜„ìœ¨ (Recall)** | **F1-Score** | **Confusion Matrix**                                |\n",
    "|-----------------------------------|----------------------|------------------------|---------------------|--------------|-----------------------------------------------------|\n",
    "| **PNEUMONIA vs NORMAL**           | 0.9655               | 0.9286                 | 0.6842              | 0.7879       | [[183   1] <br> [  6  13]]                         |\n",
    "| **COVID19 vs NORMAL**             | 0.9360               | 0.9744                 | 0.7600              | 0.8539       | [[152   1] <br> [ 12  38]]                         |\n",
    "| **Multi-class (COVID19 vs PNEUMONIA vs NORMAL)** | 0.9064 | 0.9064 | 0.9064 | 0.9064 | [[ 12   1   6] <br> [  1  39  10] <br> [  1   0 133]] |\n",
    "\n",
    "---\n",
    "\n",
    "### ê²°ë¡ \n",
    "\n",
    "- **PNEUMONIA vs NORMAL ëª¨ë¸**: ë†’ì€ ì •í™•ë„ì™€ ì •ë°€ë„, í•˜ì§€ë§Œ ì¬í˜„ìœ¨ì´ ìƒëŒ€ì ìœ¼ë¡œ ë‚®ìŠµë‹ˆë‹¤.\n",
    "- **COVID19 vs NORMAL ëª¨ë¸**: ë†’ì€ ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨ì„ ë³´ì´ë©°, ë¹„êµì  ê· í˜• ì¡íŒ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
    "- **Multi-class ëª¨ë¸**: ì„¸ ê°€ì§€ í´ë˜ìŠ¤ì— ëŒ€í•´ ê³ ë¥¸ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ë©°, F1-Scoreì™€ ì •í™•ë„ê°€ 90% ì´ìƒìœ¼ë¡œ ìš°ìˆ˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ìµœì¢… í‰ê°€**:\n",
    "- **COVID19 vs NORMAL ëª¨ë¸**ì€ ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì´ ê· í˜•ì„ ì´ë£¨ì–´ ê°€ì¥ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.\n",
    "- **Multi-class ëª¨ë¸**ì€ ì„¸ ê°€ì§€ í´ë˜ìŠ¤ë¥¼ ì˜ ë¶„ë¦¬í•˜ë©° ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1567860a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bee5d4c",
   "metadata": {},
   "source": [
    "1]Multi-classë¶„ë¥˜ì—ì„œ ì‚¬ìš©ëœ loss ê°€ ëª¨ë“  í´ë˜ìŠ¤ì— ì ì ˆí–ˆëŠ”ì§€ ë¶„ì„í•˜ê³ ,Focal loss,class-balancedlossë“±ì„ ì ìš©í•œ ì‹¤í—˜ì„ ìˆ˜í–‰í•´ë³´ì„¸ìš”.\n",
    "\n",
    "1) Loss í•¨ìˆ˜ ë¶„ì„ ë° Focal Loss, Class-Balanced Loss ì‹¤í—˜   \n",
    "Multi-class ë¶„ë¥˜ì—ì„œ ê¸°ë³¸ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” loss í•¨ìˆ˜ëŠ” Cross-Entropy Lossì…ë‹ˆë‹¤. ì´ë¥¼ Focal Lossë‚˜ Class-Balanced Lossë¡œ ë³€ê²½í•˜ì—¬ ì„±ëŠ¥ì„ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "   \n",
    "Focal Loss:   \n",
    "Focal LossëŠ” í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ loss í•¨ìˆ˜ì…ë‹ˆë‹¤. Cross-Entropy LossëŠ” í´ë˜ìŠ¤ ê°„ ë¶ˆê· í˜•ì´ ì‹¬í•  ë•Œ ì„±ëŠ¥ì´ ë–¨ì–´ì§ˆ ìˆ˜ ìˆëŠ”ë°, Focal LossëŠ” ì–´ë ¤ìš´ ìƒ˜í”Œì— ê°€ì¤‘ì¹˜ë¥¼ ì£¼ì–´ ì„±ëŠ¥ì„ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "002292aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dibaeck/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, alpha=0.25, num_classes=3):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.num_classes = num_classes\n",
    "        self.ce_loss = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = self.ce_loss(inputs, targets)\n",
    "        pt = torch.exp(-ce_loss)  # For each class\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "        return focal_loss.mean()\n",
    "    \n",
    "class ClassBalancedLoss(nn.Module):\n",
    "    def __init__(self, class_weights):\n",
    "        super(ClassBalancedLoss, self).__init__()\n",
    "        self.class_weights = class_weights\n",
    "        self.ce_loss = nn.CrossEntropyLoss(weight=self.class_weights)\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        return self.ce_loss(inputs, targets)\n",
    "    \n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "def adjust_threshold(predictions, targets, threshold=0.5):\n",
    "    pred_classes = (predictions[:, 1] > threshold).float()  # COVID-19 í´ë˜ìŠ¤ì˜ í™•ë¥ ì„ ê¸°ì¤€ìœ¼ë¡œ ì˜ˆì¸¡\n",
    "    precision = precision_score(targets, pred_classes, average='binary', pos_label=1)\n",
    "    recall = recall_score(targets, pred_classes, average='binary', pos_label=1)\n",
    "    return precision, recall\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import models\n",
    "\n",
    "class GradCAM:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "\n",
    "    def save_gradient(self, grad):\n",
    "        self.gradients = grad\n",
    "\n",
    "    def forward(self, x):\n",
    "        activations = self.model.features(x)\n",
    "        activations.register_hook(self.save_gradient)\n",
    "        return activations\n",
    "\n",
    "    def generate_gradcam(self, input_image, target_class):\n",
    "        activations = self.forward(input_image)\n",
    "        self.model.zero_grad()\n",
    "        activations[target_class].backward(retain_graph=True)\n",
    "        gradients = self.gradients\n",
    "        pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "        weighted_activations = activations * pooled_gradients.view(1, -1, 1, 1)\n",
    "        gradcam = torch.mean(weighted_activations, dim=1).squeeze()\n",
    "        gradcam = np.maximum(gradcam.cpu().detach().numpy(), 0)\n",
    "        gradcam = cv2.resize(gradcam, (input_image.size(2), input_image.size(3)))\n",
    "        return gradcam\n",
    "\n",
    "import shap\n",
    "import numpy as np\n",
    "\n",
    "# SHAPì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ í•´ì„\n",
    "def explain_with_shap(model, dataloader):\n",
    "    explainer = shap.KernelExplainer(model.predict, data=dataloader)\n",
    "    shap_values = explainer.shap_values(dataloader)\n",
    "    shap.summary_plot(shap_values, dataloader)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def analyze_confusion_matrix(predictions, targets):\n",
    "    cm = confusion_matrix(targets, predictions)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# ì˜ˆì‹œ: ì˜¤ë¶„ë¥˜ëœ ìƒ˜í”Œì— ëŒ€í•´ ê°€ì¤‘ì¹˜ë¥¼ ë” ì£¼ê¸°\n",
    "def reweight_loss_function(model, predictions, targets):\n",
    "    # ì˜ëª» ë¶„ë¥˜ëœ ìƒ˜í”Œì— ëŒ€í•´ ê°€ì¤‘ì¹˜ ì¦ê°€\n",
    "    incorrect_samples = predictions != targets\n",
    "    weights = torch.where(incorrect_samples, 2.0, 1.0)\n",
    "    loss = F.cross_entropy(predictions, targets, weight=weights)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8222df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ í•™ìŠµ ì‹œ ì‚¬ìš©ë  loss í•¨ìˆ˜ ì„¤ì •\n",
    "criterion = FocalLoss(gamma=2, alpha=0.25, num_classes=3)  # ì˜ˆì‹œë¡œ FocalLoss ì‚¬ìš©\n",
    "\n",
    "# í•™ìŠµ ê³¼ì •ì—ì„œ í•´ë‹¹ lossë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ í›ˆë ¨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73bbc3ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m thresholds = [\u001b[32m0.3\u001b[39m, \u001b[32m0.5\u001b[39m, \u001b[32m0.7\u001b[39m]  \u001b[38;5;66;03m# ì—¬ëŸ¬ threshold ê°’ ì‹œë„\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m threshold \u001b[38;5;129;01min\u001b[39;00m thresholds:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     precision, recall = adjust_threshold(\u001b[43mpredictions\u001b[49m, targets, threshold)\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThreshold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthreshold\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m -> Precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecision\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Recall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecall\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "thresholds = [0.3, 0.5, 0.7]  # ì—¬ëŸ¬ threshold ê°’ ì‹œë„\n",
    "for threshold in thresholds:\n",
    "    precision, recall = adjust_threshold(predictions, targets, threshold)\n",
    "    print(f\"Threshold: {threshold} -> Precision: {precision}, Recall: {recall}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8a18ad9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m gradcam = GradCAM(\u001b[43mmodel\u001b[49m)\n\u001b[32m      2\u001b[39m cam_output = gradcam.generate_gradcam(input_image, target_class)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# ê²°ê³¼ë¥¼ ì‹œê°í™”\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "gradcam = GradCAM(model)\n",
    "cam_output = gradcam.generate_gradcam(input_image, target_class)\n",
    "# ê²°ê³¼ë¥¼ ì‹œê°í™”\n",
    "plt.imshow(cam_output, cmap='jet')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68912131",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dibk311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
