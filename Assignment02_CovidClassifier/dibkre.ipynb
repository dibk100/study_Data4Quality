{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d09a5f0",
   "metadata": {},
   "source": [
    "---\n",
    "## **ğŸ“Š Flow**   \n",
    "> step01 : Data   \n",
    "> - ë°ì´í„° ì¤€ë¹„ ë° ë¶„ì„   \n",
    "> - ë°ì´í„° ì „ì²˜ë¦¬\n",
    "   #   \n",
    "> setp02 : ëª¨ë¸ ë¹„êµ     \n",
    "> - ResNet50, EfficientNet,VGG16\n",
    "> - ëª¨ë¸ í•™ìŠµ\n",
    "> - ì„±ëŠ¥í‰ê°€ : ì •í™•ë„ ì¬í˜„ìœ¨ f1\n",
    "   #\n",
    "> setp03 : ë¶„ì„ ì‹¤í—˜   \n",
    "> - Focal Loss, Class-balanced Loss ì ìš©.   \n",
    "> - Precision-Recall Trade-off   \n",
    "> - XAI ê¸°ë²•   \n",
    "> - ì˜¤ë¶„ë¥˜ ë¶„ì„   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bdfc80",
   "metadata": {},
   "source": [
    "---\n",
    "> ### step01 : Data   \n",
    "> - ë°ì´í„° ì¤€ë¹„ ë° ë¶„ì„   \n",
    "> - ë°ì´í„° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed597957",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataprocessing import *\n",
    "\n",
    "# ë°ì´í„° ê²½ë¡œ\n",
    "data_path = '/home/dibaeck/sketch/study_Data4Quality/task02_CovidClassifier/COVID19_1K'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd80077",
   "metadata": {},
   "source": [
    "---\n",
    ">> ë°ì´í„° ì‚¬ì´ì¦ˆ ë‹¤ë¦„ --> TASK : ë°ì´í„° ë¦¬ì‚¬ì´ì¦ˆ  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84997161",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_image_sizes(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f345db94",
   "metadata": {},
   "source": [
    "---\n",
    ">> í´ë˜ìŠ¤ ë¶ˆê· í˜• : COVID19 ë°ì´í„°ê°€ ì ìŒ.  --> TASK : Data Augmentation   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb00a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_and_visualize_images(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9793bbb",
   "metadata": {},
   "source": [
    "í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²° ì „ëµ : WeightedRandomSampler + FocalLoss\n",
    "\n",
    "| ì „ëµ               | ì„¤ëª…                                                                 |\n",
    "|--------------------|----------------------------------------------------------------------|\n",
    "| **WeightedRandomSampler**          | ìˆ˜ í´ë˜ìŠ¤ë¥¼ ë” ìì£¼ ë½‘íˆê²Œ í•˜ëŠ” ìƒ˜í”Œë§ ë°©ì‹                |\n",
    "| **Focal Loss**     | ì†Œìˆ˜ í´ë˜ìŠ¤ì˜ ì–´ë ¤ìš´ ìƒ˜í”Œì— ë” ì§‘ì¤‘í•˜ëŠ” loss function(ì˜ë£Œ ì´ë¯¸ì§€ì—ì„œ ì„±ëŠ¥ ê°œì„ ì— íš¨ê³¼ì )                               |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503ffc26",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abac0d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## setting \n",
    "from dataprocessing import *\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "# ë°ì´í„° ê²½ë¡œ\n",
    "data_path = '/home/dibaeck/sketch/study_Data4Quality/task02_CovidClassifier/COVID19_1K'\n",
    "\n",
    "# ë°ì´í„° ì •ê·œí™” ë° ë¦¬ì‚¬ì´ì¦ˆ, í…ì„œí™”\n",
    "transform = get_transform()\n",
    "\n",
    "no1_target_classes = ['PNEUMONIA', 'NORMAL']\n",
    "train_dataset1, val_dataset1, test_dataset1 = get_customdatasets(data_path, transform,no1_target_classes)\n",
    "train_loader1,val_loader1,test_loader1 = get_dataloaders(train_dataset1,val_dataset1,test_dataset1,batch_size=32)\n",
    "\n",
    "no2_target_classes = ['COVID19', 'NORMAL']\n",
    "train_dataset2, val_dataset2, test_dataset2 = get_customdatasets(data_path, transform,no2_target_classes)\n",
    "train_loader2,val_loader2,test_loader2 = get_dataloaders(train_dataset2,val_dataset2,test_dataset2,batch_size=32)\n",
    "\n",
    "no3_target_classes = ['NORMAL',\"PNEUMONIA\",'COVID19']\n",
    "train_dataset3, val_dataset3, test_dataset3 = get_customdatasets(data_path, transform,no3_target_classes)\n",
    "train_loader3,val_loader3,test_loader3 = get_dataloaders(train_dataset2,val_dataset2,test_dataset2,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e779971a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dibaeck/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/dibaeck/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /home/dibaeck/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30.8M/30.8M [00:00<00:00, 56.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "from models import *\n",
    "import torch.optim as optim\n",
    "\n",
    "# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# Binary Classification (PNEUMONIA vs NORMAL)\n",
    "binary_model_pneumonia_vs_normal = CustomDenseNet(num_classes=2)\n",
    "\n",
    "# Binary Classification (COVID19 vs NORMAL)\n",
    "binary_model_covid19_vs_normal = CustomDenseNet(num_classes=2)\n",
    "\n",
    "# Multi-class Classification (COVID19 vs PNEUMONIA vs NORMAL)\n",
    "multi_class_model = CustomDenseNet(num_classes=3)\n",
    "\n",
    "\n",
    "# ì§€í‘œ ì„¤ì •\n",
    "# ê°ê°ì˜ ëª¨ë¸ì— ëŒ€í•´ ì´ì§„ ë¶„ë¥˜ì—ì„œëŠ” Binary Cross Entropyë¥¼, ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ì—ì„œëŠ” Cross Entropyë¥¼ ì‚¬ìš©\n",
    "# ì´ì§„ ë¶„ë¥˜ ëª¨ë¸ (PNEUMONIA vs NORMAL, COVID19 vs NORMAL) \n",
    "criterion_binary = nn.BCEWithLogitsLoss()  # ì´ì§„ ë¶„ë¥˜ì—ì„œ ì‚¬ìš©\n",
    "optimizer_binary = optim.Adam(binary_model_pneumonia_vs_normal.parameters(), lr=0.001)\n",
    "\n",
    "# ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ ëª¨ë¸ (COVID19 vs PNEUMONIA vs NORMAL)\n",
    "criterion_multi_class = nn.CrossEntropyLoss()  # ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ì—ì„œ ì‚¬ìš©\n",
    "optimizer_multi_class = optim.Adam(multi_class_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d233fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "GET was unable to find an engine to execute this computation",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ëª¨ë¸ í•™ìŠµ\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mbinary_model_pneumonia_vs_normal\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion_binary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_binary\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sketch/study_Data4Quality/task02_CovidClassifier/models.py:53\u001b[39m, in \u001b[36mCustomDenseNet.model_train\u001b[39m\u001b[34m(self, train_loader, criterion, optimizer, num_epochs)\u001b[39m\n\u001b[32m     51\u001b[39m labels = labels.to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m     52\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.num_classes == \u001b[32m2\u001b[39m:       \u001b[38;5;66;03m# ì´ì§„ë¶„ë¥˜\u001b[39;00m\n\u001b[32m     56\u001b[39m     labels = labels.float()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1496\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1499\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1500\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1501\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1502\u001b[39m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[32m   1503\u001b[39m full_backward_hooks, non_full_backward_hooks = [], []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sketch/study_Data4Quality/task02_CovidClassifier/models.py:35\u001b[39m, in \u001b[36mCustomDenseNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdensenet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1496\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1499\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1500\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1501\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1502\u001b[39m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[32m   1503\u001b[39m full_backward_hooks, non_full_backward_hooks = [], []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/torchvision/models/densenet.py:213\u001b[39m, in \u001b[36mDenseNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m     out = F.relu(features, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    215\u001b[39m     out = F.adaptive_avg_pool2d(out, (\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1496\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1499\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1500\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1501\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1502\u001b[39m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[32m   1503\u001b[39m full_backward_hooks, non_full_backward_hooks = [], []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1496\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1499\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1500\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1501\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1502\u001b[39m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[32m   1503\u001b[39m full_backward_hooks, non_full_backward_hooks = [], []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/torch/nn/modules/conv.py:463\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    462\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m463\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/torch/nn/modules/conv.py:459\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m'\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(F.pad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode),\n\u001b[32m    457\u001b[39m                     weight, bias, \u001b[38;5;28mself\u001b[39m.stride,\n\u001b[32m    458\u001b[39m                     _pair(\u001b[32m0\u001b[39m), \u001b[38;5;28mself\u001b[39m.dilation, \u001b[38;5;28mself\u001b[39m.groups)\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: GET was unable to find an engine to execute this computation"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ í•™ìŠµ\n",
    "binary_model_pneumonia_vs_normal.model_train(train_loader1, criterion_binary, optimizer_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115ec338",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_model_covid19_vs_normal.model_train(train_loader2, criterion_binary, optimizer_binary)\n",
    "\n",
    "multi_class_model.model_train(train_loader3,criterion_multi_class,optimizer_multi_class)\n",
    "ë­ê°€ ë¬¸ì œì¸ë°ã…œã… ã…œã… ã…œã… ã…œ\n",
    "\n",
    "\n",
    "# ëª¨ë¸ í‰ê°€\n",
    "binary_model_pneumonia_vs_normal.model_eval(test_loader)\n",
    "binary_model_covid19_vs_normal.model_eval(test_loader)\n",
    "multi_class_model.model_eval(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed3ca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€ ì‹¤í–‰\n",
    "train_and_evaluate_models(train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a879e7a3",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ\n",
    "\n",
    "| **ëª¨ë¸**                          | **ì •í™•ë„ (Accuracy)** | **ì •ë°€ë„ (Precision)** | **ì¬í˜„ìœ¨ (Recall)** | **F1-Score** | **Confusion Matrix**                                |\n",
    "|-----------------------------------|----------------------|------------------------|---------------------|--------------|-----------------------------------------------------|\n",
    "| **PNEUMONIA vs NORMAL**           | 0.9655               | 0.9286                 | 0.6842              | 0.7879       | [[183   1] <br> [  6  13]]                         |\n",
    "| **COVID19 vs NORMAL**             | 0.9360               | 0.9744                 | 0.7600              | 0.8539       | [[152   1] <br> [ 12  38]]                         |\n",
    "| **Multi-class (COVID19 vs PNEUMONIA vs NORMAL)** | 0.9064 | 0.9064 | 0.9064 | 0.9064 | [[ 12   1   6] <br> [  1  39  10] <br> [  1   0 133]] |\n",
    "\n",
    "---\n",
    "\n",
    "### ê²°ë¡ \n",
    "\n",
    "- **PNEUMONIA vs NORMAL ëª¨ë¸**: ë†’ì€ ì •í™•ë„ì™€ ì •ë°€ë„, í•˜ì§€ë§Œ ì¬í˜„ìœ¨ì´ ìƒëŒ€ì ìœ¼ë¡œ ë‚®ìŠµë‹ˆë‹¤.\n",
    "- **COVID19 vs NORMAL ëª¨ë¸**: ë†’ì€ ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨ì„ ë³´ì´ë©°, ë¹„êµì  ê· í˜• ì¡íŒ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
    "- **Multi-class ëª¨ë¸**: ì„¸ ê°€ì§€ í´ë˜ìŠ¤ì— ëŒ€í•´ ê³ ë¥¸ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ë©°, F1-Scoreì™€ ì •í™•ë„ê°€ 90% ì´ìƒìœ¼ë¡œ ìš°ìˆ˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ìµœì¢… í‰ê°€**:\n",
    "- **COVID19 vs NORMAL ëª¨ë¸**ì€ ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì´ ê· í˜•ì„ ì´ë£¨ì–´ ê°€ì¥ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.\n",
    "- **Multi-class ëª¨ë¸**ì€ ì„¸ ê°€ì§€ í´ë˜ìŠ¤ë¥¼ ì˜ ë¶„ë¦¬í•˜ë©° ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1567860a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bee5d4c",
   "metadata": {},
   "source": [
    "1]Multi-classë¶„ë¥˜ì—ì„œ ì‚¬ìš©ëœ loss ê°€ ëª¨ë“  í´ë˜ìŠ¤ì— ì ì ˆí–ˆëŠ”ì§€ ë¶„ì„í•˜ê³ ,Focal loss,class-balancedlossë“±ì„ ì ìš©í•œ ì‹¤í—˜ì„ ìˆ˜í–‰í•´ë³´ì„¸ìš”.\n",
    "\n",
    "1) Loss í•¨ìˆ˜ ë¶„ì„ ë° Focal Loss, Class-Balanced Loss ì‹¤í—˜   \n",
    "Multi-class ë¶„ë¥˜ì—ì„œ ê¸°ë³¸ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” loss í•¨ìˆ˜ëŠ” Cross-Entropy Lossì…ë‹ˆë‹¤. ì´ë¥¼ Focal Lossë‚˜ Class-Balanced Lossë¡œ ë³€ê²½í•˜ì—¬ ì„±ëŠ¥ì„ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "   \n",
    "Focal Loss:   \n",
    "Focal LossëŠ” í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ loss í•¨ìˆ˜ì…ë‹ˆë‹¤. Cross-Entropy LossëŠ” í´ë˜ìŠ¤ ê°„ ë¶ˆê· í˜•ì´ ì‹¬í•  ë•Œ ì„±ëŠ¥ì´ ë–¨ì–´ì§ˆ ìˆ˜ ìˆëŠ”ë°, Focal LossëŠ” ì–´ë ¤ìš´ ìƒ˜í”Œì— ê°€ì¤‘ì¹˜ë¥¼ ì£¼ì–´ ì„±ëŠ¥ì„ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002292aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, alpha=0.25, num_classes=3):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.num_classes = num_classes\n",
    "        self.ce_loss = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = self.ce_loss(inputs, targets)\n",
    "        pt = torch.exp(-ce_loss)  # For each class\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "        return focal_loss.mean()\n",
    "    \n",
    "class ClassBalancedLoss(nn.Module):\n",
    "    def __init__(self, class_weights):\n",
    "        super(ClassBalancedLoss, self).__init__()\n",
    "        self.class_weights = class_weights\n",
    "        self.ce_loss = nn.CrossEntropyLoss(weight=self.class_weights)\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        return self.ce_loss(inputs, targets)\n",
    "    \n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "def adjust_threshold(predictions, targets, threshold=0.5):\n",
    "    pred_classes = (predictions[:, 1] > threshold).float()  # COVID-19 í´ë˜ìŠ¤ì˜ í™•ë¥ ì„ ê¸°ì¤€ìœ¼ë¡œ ì˜ˆì¸¡\n",
    "    precision = precision_score(targets, pred_classes, average='binary', pos_label=1)\n",
    "    recall = recall_score(targets, pred_classes, average='binary', pos_label=1)\n",
    "    return precision, recall\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import models\n",
    "\n",
    "class GradCAM:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "\n",
    "    def save_gradient(self, grad):\n",
    "        self.gradients = grad\n",
    "\n",
    "    def forward(self, x):\n",
    "        activations = self.model.features(x)\n",
    "        activations.register_hook(self.save_gradient)\n",
    "        return activations\n",
    "\n",
    "    def generate_gradcam(self, input_image, target_class):\n",
    "        activations = self.forward(input_image)\n",
    "        self.model.zero_grad()\n",
    "        activations[target_class].backward(retain_graph=True)\n",
    "        gradients = self.gradients\n",
    "        pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "        weighted_activations = activations * pooled_gradients.view(1, -1, 1, 1)\n",
    "        gradcam = torch.mean(weighted_activations, dim=1).squeeze()\n",
    "        gradcam = np.maximum(gradcam.cpu().detach().numpy(), 0)\n",
    "        gradcam = cv2.resize(gradcam, (input_image.size(2), input_image.size(3)))\n",
    "        return gradcam\n",
    "\n",
    "import shap\n",
    "import numpy as np\n",
    "\n",
    "# SHAPì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ í•´ì„\n",
    "def explain_with_shap(model, dataloader):\n",
    "    explainer = shap.KernelExplainer(model.predict, data=dataloader)\n",
    "    shap_values = explainer.shap_values(dataloader)\n",
    "    shap.summary_plot(shap_values, dataloader)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def analyze_confusion_matrix(predictions, targets):\n",
    "    cm = confusion_matrix(targets, predictions)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# ì˜ˆì‹œ: ì˜¤ë¶„ë¥˜ëœ ìƒ˜í”Œì— ëŒ€í•´ ê°€ì¤‘ì¹˜ë¥¼ ë” ì£¼ê¸°\n",
    "def reweight_loss_function(model, predictions, targets):\n",
    "    # ì˜ëª» ë¶„ë¥˜ëœ ìƒ˜í”Œì— ëŒ€í•´ ê°€ì¤‘ì¹˜ ì¦ê°€\n",
    "    incorrect_samples = predictions != targets\n",
    "    weights = torch.where(incorrect_samples, 2.0, 1.0)\n",
    "    loss = F.cross_entropy(predictions, targets, weight=weights)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8222df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ í•™ìŠµ ì‹œ ì‚¬ìš©ë  loss í•¨ìˆ˜ ì„¤ì •\n",
    "criterion = FocalLoss(gamma=2, alpha=0.25, num_classes=3)  # ì˜ˆì‹œë¡œ FocalLoss ì‚¬ìš©\n",
    "\n",
    "# í•™ìŠµ ê³¼ì •ì—ì„œ í•´ë‹¹ lossë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ í›ˆë ¨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bbc3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.3, 0.5, 0.7]  # ì—¬ëŸ¬ threshold ê°’ ì‹œë„\n",
    "for threshold in thresholds:\n",
    "    precision, recall = adjust_threshold(predictions, targets, threshold)\n",
    "    print(f\"Threshold: {threshold} -> Precision: {precision}, Recall: {recall}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a18ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradcam = GradCAM(model)\n",
    "cam_output = gradcam.generate_gradcam(input_image, target_class)\n",
    "# ê²°ê³¼ë¥¼ ì‹œê°í™”\n",
    "plt.imshow(cam_output, cmap='jet')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68912131",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dibk311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
